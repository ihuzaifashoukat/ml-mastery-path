{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3b316a",
   "metadata": {},
   "source": [
    "# ðŸ§  Deep Learning: Complete Guide (Beginner to Advanced)\n",
    "\n",
    "## Master Neural Networks with PyTorch\n",
    "\n",
    "This comprehensive guide takes you from **zero to hero** in Deep Learning:\n",
    "\n",
    "### What You'll Learn:\n",
    "\n",
    "| Level | Topics |\n",
    "|-------|--------|\n",
    "| **ðŸŸ¢ Beginner** | Perceptrons, Activation Functions, Forward/Backward Propagation |\n",
    "| **ðŸŸ¡ Intermediate** | CNNs, RNNs, LSTMs, Regularization, Batch Normalization |\n",
    "| **ðŸ”´ Advanced** | Transformers, Attention, GANs, Transfer Learning, Custom Architectures |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ What is Deep Learning?\n",
    "\n",
    "**Deep Learning** = Machine Learning with **neural networks** that have multiple layers (hence \"deep\").\n",
    "\n",
    "### Why Deep Learning?\n",
    "\n",
    "| Traditional ML | Deep Learning |\n",
    "|----------------|---------------|\n",
    "| Requires feature engineering | Learns features automatically |\n",
    "| Works well on structured data | Excels at images, text, audio |\n",
    "| Interpretable | Often \"black box\" |\n",
    "| Less data needed | Needs lots of data |\n",
    "| CPU sufficient | GPU recommended |\n",
    "\n",
    "### The Neural Network Analogy\n",
    "\n",
    "```\n",
    "Biological Neuron              Artificial Neuron\n",
    "      â”Œâ”€â”€â”€â”                         â”Œâ”€â”€â”€â”\n",
    "â”€â”€â”€â”€â”€â”€â”¤   â”‚                   xâ‚â”€â”€â”€â”€â”¤   â”‚\n",
    "â”€â”€â”€â”€â”€â”€â”¤ â—‹ â”œâ”€â”€â”€â”€â”€â”€             xâ‚‚â”€â”€â”€â”€â”¤ Î£ â”œâ”€â”€â†’ f(z) â”€â”€â†’ output\n",
    "â”€â”€â”€â”€â”€â”€â”¤   â”‚                   xâ‚ƒâ”€â”€â”€â”€â”¤   â”‚\n",
    "      â””â”€â”€â”€â”˜                         â””â”€â”€â”€â”˜\n",
    "  Dendrites â†’ Soma â†’ Axon       Inputs â†’ Weighted Sum â†’ Activation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace4db5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“¦ Section 1: Setup & Installation\n",
    "\n",
    "We'll use **PyTorch** - the most popular deep learning framework for research and production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a59f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch (uncomment based on your system)\n",
    "# !pip install torch torchvision torchaudio  # CPU only\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # CUDA 11.8\n",
    "\n",
    "# Core imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# Torchvision for datasets and transforms\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10, FashionMNIST\n",
    "\n",
    "# Utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"ðŸ–¥ï¸  SYSTEM INFO\")\n",
    "print(\"=\"*50)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU detected - training will be slower\")\n",
    "    print(\"   Consider using Google Colab for free GPU access\")\n",
    "\n",
    "print(\"\\nâœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb61e01",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŸ¢ PART 1: BEGINNER - Neural Network Fundamentals\n",
    "\n",
    "## Section 2: Tensors - The Building Blocks\n",
    "\n",
    "**Tensors** are the fundamental data structure in deep learning - like NumPy arrays but with GPU support!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENSORS 101\n",
    "print(\"ðŸ“Š TENSOR BASICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Creating tensors\n",
    "scalar = torch.tensor(3.14)           # 0D tensor (scalar)\n",
    "vector = torch.tensor([1, 2, 3, 4])   # 1D tensor (vector)\n",
    "matrix = torch.tensor([[1, 2], [3, 4], [5, 6]])  # 2D tensor (matrix)\n",
    "tensor_3d = torch.randn(2, 3, 4)      # 3D tensor\n",
    "\n",
    "print(f\"Scalar: {scalar}, shape: {scalar.shape}\")\n",
    "print(f\"Vector: {vector}, shape: {vector.shape}\")\n",
    "print(f\"Matrix shape: {matrix.shape}\")\n",
    "print(f\"3D Tensor shape: {tensor_3d.shape}\")\n",
    "\n",
    "# Common tensor operations\n",
    "print(\"\\nðŸ”¢ TENSOR OPERATIONS\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "a = torch.tensor([[1., 2.], [3., 4.]])\n",
    "b = torch.tensor([[5., 6.], [7., 8.]])\n",
    "\n",
    "print(f\"a + b =\\n{a + b}\")\n",
    "print(f\"\\na @ b (matrix multiply) =\\n{a @ b}\")\n",
    "print(f\"\\na.T (transpose) =\\n{a.T}\")\n",
    "print(f\"\\na.mean() = {a.mean()}\")\n",
    "print(f\"a.sum() = {a.sum()}\")\n",
    "\n",
    "# GPU operations\n",
    "print(\"\\nðŸš€ GPU ACCELERATION\")\n",
    "print(\"-\"*50)\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = a.to(device)\n",
    "    print(f\"Tensor on GPU: {gpu_tensor.device}\")\n",
    "else:\n",
    "    print(\"GPU not available - tensor stays on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e2bced",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: The Perceptron - Simplest Neural Network\n",
    "\n",
    "A **perceptron** is a single artificial neuron:\n",
    "\n",
    "$$y = f\\left(\\sum_{i=1}^{n} w_i x_i + b\\right) = f(W^T X + b)$$\n",
    "\n",
    "Where:\n",
    "- $x_i$ = inputs\n",
    "- $w_i$ = weights (learned)\n",
    "- $b$ = bias (learned)\n",
    "- $f$ = activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ff324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A PERCEPTRON FROM SCRATCH\n",
    "class PerceptronFromScratch:\n",
    "    \"\"\"\n",
    "    Single neuron that can learn to classify linearly separable data.\n",
    "    This is the foundation of ALL neural networks!\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features):\n",
    "        # Initialize weights randomly\n",
    "        self.weights = np.random.randn(n_features) * 0.01\n",
    "        self.bias = 0.0\n",
    "    \n",
    "    def activation(self, z):\n",
    "        \"\"\"Step function: output 1 if z > 0, else 0\"\"\"\n",
    "        return (z > 0).astype(int)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward pass: compute predictions\"\"\"\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.activation(z)\n",
    "    \n",
    "    def train(self, X, y, learning_rate=0.1, epochs=100):\n",
    "        \"\"\"Train using perceptron learning rule\"\"\"\n",
    "        history = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            errors = 0\n",
    "            for xi, yi in zip(X, y):\n",
    "                # Forward pass\n",
    "                prediction = self.forward(xi.reshape(1, -1))[0]\n",
    "                \n",
    "                # Calculate error\n",
    "                error = yi - prediction\n",
    "                \n",
    "                # Update weights: w = w + lr * error * x\n",
    "                self.weights += learning_rate * error * xi\n",
    "                self.bias += learning_rate * error\n",
    "                \n",
    "                errors += abs(error)\n",
    "            \n",
    "            accuracy = 1 - errors / len(y)\n",
    "            history.append(accuracy)\n",
    "            \n",
    "            if epoch % 20 == 0:\n",
    "                print(f\"Epoch {epoch}: Accuracy = {accuracy:.4f}\")\n",
    "        \n",
    "        return history\n",
    "\n",
    "# Create linearly separable data (AND gate)\n",
    "print(\"ðŸ§  PERCEPTRON: Learning AND Gate\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_and = np.array([0, 0, 0, 1])  # AND gate output\n",
    "\n",
    "perceptron = PerceptronFromScratch(n_features=2)\n",
    "history = perceptron.train(X_and, y_and, epochs=50)\n",
    "\n",
    "print(f\"\\nFinal weights: {perceptron.weights}\")\n",
    "print(f\"Final bias: {perceptron.bias}\")\n",
    "print(f\"\\nPredictions:\")\n",
    "for xi, yi in zip(X_and, y_and):\n",
    "    pred = perceptron.forward(xi.reshape(1, -1))[0]\n",
    "    print(f\"  {xi} â†’ {pred} (expected: {yi}) {'âœ…' if pred == yi else 'âŒ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62992db1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Activation Functions - Adding Non-linearity\n",
    "\n",
    "Without activation functions, neural networks would just be linear models!\n",
    "\n",
    "### Common Activation Functions:\n",
    "\n",
    "| Function | Formula | Range | Use Case |\n",
    "|----------|---------|-------|----------|\n",
    "| **Sigmoid** | $\\frac{1}{1+e^{-x}}$ | (0, 1) | Binary classification output |\n",
    "| **Tanh** | $\\frac{e^x - e^{-x}}{e^x + e^{-x}}$ | (-1, 1) | Hidden layers (centered) |\n",
    "| **ReLU** | $\\max(0, x)$ | [0, âˆž) | Hidden layers (default choice) |\n",
    "| **Leaky ReLU** | $\\max(0.01x, x)$ | (-âˆž, âˆž) | Prevents dead neurons |\n",
    "| **Softmax** | $\\frac{e^{x_i}}{\\sum e^{x_j}}$ | (0, 1), sum=1 | Multi-class output |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Activation Functions\n",
    "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "def tanh(x): return np.tanh(x)\n",
    "def relu(x): return np.maximum(0, x)\n",
    "def leaky_relu(x, alpha=0.1): return np.where(x > 0, x, alpha * x)\n",
    "def softmax(x): return np.exp(x) / np.sum(np.exp(x))\n",
    "def gelu(x): return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi) * (x + 0.044715 * x**3)))\n",
    "\n",
    "x = np.linspace(-5, 5, 200)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "activations = [\n",
    "    (sigmoid, \"Sigmoid\", \"Ïƒ(x) = 1/(1+e^(-x))\"),\n",
    "    (tanh, \"Tanh\", \"tanh(x)\"),\n",
    "    (relu, \"ReLU\", \"max(0, x)\"),\n",
    "    (leaky_relu, \"Leaky ReLU\", \"max(0.1x, x)\"),\n",
    "    (gelu, \"GELU\", \"xÂ·Î¦(x) [used in Transformers]\"),\n",
    "]\n",
    "\n",
    "for ax, (func, name, formula) in zip(axes.flat[:5], activations):\n",
    "    y = func(x)\n",
    "    ax.plot(x, y, 'b-', linewidth=2)\n",
    "    ax.axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
    "    ax.axvline(x=0, color='k', linestyle='-', linewidth=0.5)\n",
    "    ax.set_xlim(-5, 5)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax.set_title(f'{name}\\n{formula}', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Softmax visualization\n",
    "ax = axes[1, 2]\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "probs = softmax(logits)\n",
    "bars = ax.bar(['Class A', 'Class B', 'Class C'], probs, color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "ax.set_title('Softmax Output\\n[2.0, 1.0, 0.1] â†’ probabilities')\n",
    "ax.set_ylabel('Probability')\n",
    "for bar, prob in zip(bars, probs):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{prob:.3f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('ðŸŽ¯ Activation Functions', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ KEY INSIGHTS:\")\n",
    "print(\"   â€¢ ReLU: Fast, works well, but can 'die' (always output 0)\")\n",
    "print(\"   â€¢ Sigmoid/Tanh: Vanishing gradient problem in deep networks\")\n",
    "print(\"   â€¢ GELU: Smoother than ReLU, used in modern transformers\")\n",
    "print(\"   â€¢ Softmax: Converts logits to probabilities (multi-class output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751ac13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Building Your First Neural Network in PyTorch\n",
    "\n",
    "Let's build a Multi-Layer Perceptron (MLP) to classify handwritten digits!\n",
    "\n",
    "### The MNIST Dataset\n",
    "- 60,000 training images, 10,000 test images\n",
    "- 28Ã—28 grayscale images of digits 0-9\n",
    "- The \"Hello World\" of deep learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Dataset\n",
    "print(\"ðŸ“¥ LOADING MNIST DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define transforms: convert to tensor and normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor [0, 1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "])\n",
    "\n",
    "# Download and load datasets\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Image shape: {train_dataset[0][0].shape}\")\n",
    "print(f\"Number of classes: 10 (digits 0-9)\")\n",
    "\n",
    "# Visualize some samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img, label = train_dataset[i]\n",
    "    ax.imshow(img.squeeze(), cmap='gray')\n",
    "    ax.set_title(f'Label: {label}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('ðŸ“· MNIST Samples', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A NEURAL NETWORK IN PYTORCH\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron for MNIST classification.\n",
    "    \n",
    "    Architecture:\n",
    "        Input (784) â†’ Hidden1 (256) â†’ Hidden2 (128) â†’ Output (10)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.flatten = nn.Flatten()  # 28x28 â†’ 784\n",
    "        self.fc1 = nn.Linear(784, 256)   # First hidden layer\n",
    "        self.fc2 = nn.Linear(256, 128)   # Second hidden layer\n",
    "        self.fc3 = nn.Linear(128, 10)    # Output layer (10 classes)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        This defines how data flows through the layers.\n",
    "        \"\"\"\n",
    "        x = self.flatten(x)        # Flatten: [batch, 1, 28, 28] â†’ [batch, 784]\n",
    "        x = F.relu(self.fc1(x))    # Hidden 1 + ReLU activation\n",
    "        x = self.dropout(x)        # Dropout\n",
    "        x = F.relu(self.fc2(x))    # Hidden 2 + ReLU activation\n",
    "        x = self.dropout(x)        # Dropout\n",
    "        x = self.fc3(x)            # Output (raw logits, no activation)\n",
    "        return x\n",
    "\n",
    "# Create model and move to device\n",
    "model = MLP().to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"ðŸ§  NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\"*50)\n",
    "print(model)\n",
    "print(f\"\\nðŸ“Š Parameters: {total_params:,} total\")\n",
    "\n",
    "# Visualize architecture\n",
    "print(\"\\nðŸ“ Layer Shapes:\")\n",
    "print(\"   Input:  [batch, 1, 28, 28]\")\n",
    "print(\"   Flatten â†’ [batch, 784]\")\n",
    "print(\"   FC1:    [batch, 784] â†’ [batch, 256]\")\n",
    "print(\"   FC2:    [batch, 256] â†’ [batch, 128]\")\n",
    "print(\"   FC3:    [batch, 128] â†’ [batch, 10]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f6ad26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: The Training Loop - Forward & Backward Propagation\n",
    "\n",
    "### The Deep Learning Training Algorithm:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        TRAINING LOOP                                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  FOR each epoch:                                                        â”‚\n",
    "â”‚    FOR each batch:                                                      â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚      1. ðŸ“¤ FORWARD PASS                                                 â”‚\n",
    "â”‚         â””â”€> Pass input through network â†’ get predictions                â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚      2. ðŸ“‰ COMPUTE LOSS                                                 â”‚\n",
    "â”‚         â””â”€> Compare predictions with true labels                        â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚      3. ðŸ“¥ BACKWARD PASS (Backpropagation)                              â”‚\n",
    "â”‚         â””â”€> Compute gradients: âˆ‚Loss/âˆ‚weights                           â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚      4. ðŸ”„ UPDATE WEIGHTS                                               â”‚\n",
    "â”‚         â””â”€> weights = weights - learning_rate Ã— gradients               â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚      5. ðŸ§¹ ZERO GRADIENTS                                               â”‚\n",
    "â”‚         â””â”€> Reset gradients for next iteration                          â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16368507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING CONFIGURATION\n",
    "print(\"âš™ï¸ TRAINING CONFIGURATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Loss function: Cross-Entropy for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: Adam (adaptive learning rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler (optional but recommended)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "print(f\"Loss Function: CrossEntropyLoss\")\n",
    "print(f\"Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"Scheduler: StepLR (reduce LR by 0.5 every 5 epochs)\")\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()  # Set to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        # Move data to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # 1. Zero gradients (IMPORTANT!)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # 3. Compute loss\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        # 4. Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate on test set\"\"\"\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # No gradients needed for evaluation\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "print(\"\\nâœ… Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a63582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL!\n",
    "print(\"ðŸ‹ï¸ TRAINING NEURAL NETWORK\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "num_epochs = 10\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch [{epoch+1:2d}/{num_epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Training complete! Final test accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training progress\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['test_loss'], label='Test Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('ðŸ“‰ Training & Test Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "axes[1].plot(history['test_acc'], label='Test Accuracy', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('ðŸ“ˆ Training & Test Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ TRAINING INSIGHTS:\")\n",
    "print(\"   â€¢ Loss should decrease over epochs\")\n",
    "print(\"   â€¢ If test loss increases while train loss decreases â†’ Overfitting!\")\n",
    "print(\"   â€¢ Gap between train/test accuracy indicates generalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1077be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŸ¡ PART 2: INTERMEDIATE - Convolutional Neural Networks\n",
    "\n",
    "## Section 7: CNNs - The Computer Vision Workhorse\n",
    "\n",
    "**Convolutional Neural Networks** are designed for image data:\n",
    "- **Convolution**: Detect local patterns (edges, textures, shapes)\n",
    "- **Pooling**: Reduce spatial dimensions, add translation invariance\n",
    "- **Feature Hierarchy**: Low-level â†’ Mid-level â†’ High-level features\n",
    "\n",
    "### Why CNNs beat MLPs for images?\n",
    "| MLP | CNN |\n",
    "|-----|-----|\n",
    "| Treats pixels independently | Preserves spatial structure |\n",
    "| Many parameters (784 Ã— 256 = 200K) | Fewer params (shared weights) |\n",
    "| No translation invariance | Detects patterns anywhere |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549298a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how convolution works\n",
    "print(\"ðŸ” UNDERSTANDING CONVOLUTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a simple image\n",
    "image = torch.tensor([\n",
    "    [0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Edge detection kernels\n",
    "vertical_edge = torch.tensor([\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "horizontal_edge = torch.tensor([\n",
    "    [-1, -1, -1],\n",
    "    [ 0,  0,  0],\n",
    "    [ 1,  1,  1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Apply convolution\n",
    "image_batch = image.unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "v_kernel = vertical_edge.unsqueeze(0).unsqueeze(0)\n",
    "h_kernel = horizontal_edge.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "v_edges = F.conv2d(image_batch, v_kernel, padding=1)\n",
    "h_edges = F.conv2d(image_batch, h_kernel, padding=1)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 5, figsize=(16, 3))\n",
    "\n",
    "axes[0].imshow(image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "axes[1].imshow(vertical_edge, cmap='RdBu', vmin=-1, vmax=1)\n",
    "axes[1].set_title('Vertical Edge Kernel')\n",
    "\n",
    "axes[2].imshow(v_edges.squeeze(), cmap='RdBu')\n",
    "axes[2].set_title('Vertical Edges Detected')\n",
    "\n",
    "axes[3].imshow(horizontal_edge, cmap='RdBu', vmin=-1, vmax=1)\n",
    "axes[3].set_title('Horizontal Edge Kernel')\n",
    "\n",
    "axes[4].imshow(h_edges.squeeze(), cmap='RdBu')\n",
    "axes[4].set_title('Horizontal Edges Detected')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('ðŸ” Convolution: Kernel slides over image, detecting patterns', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ KEY INSIGHT: The kernel 'slides' over the image,\")\n",
    "print(\"   computing dot product at each position to detect patterns!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11406f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A CNN FOR IMAGE CLASSIFICATION\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for MNIST/CIFAR classification.\n",
    "    \n",
    "    Architecture:\n",
    "        Conv1 â†’ ReLU â†’ Pool â†’ Conv2 â†’ ReLU â†’ Pool â†’ FC1 â†’ FC2 â†’ Output\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)   # 28x28 â†’ 28x28\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 14x14 â†’ 14x14\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 7x7 â†’ 7x7\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Reduces size by half\n",
    "        \n",
    "        # Batch normalization (stabilizes training)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)  # After pooling: 28â†’14â†’7â†’3\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv block 1: Conv â†’ BN â†’ ReLU â†’ Pool\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # 28x28 â†’ 14x14\n",
    "        \n",
    "        # Conv block 2\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # 14x14 â†’ 7x7\n",
    "        \n",
    "        # Conv block 3\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # 7x7 â†’ 3x3\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)  # [batch, 128, 3, 3] â†’ [batch, 1152]\n",
    "        \n",
    "        # Fully connected\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create CNN model\n",
    "cnn_model = CNN(num_classes=10).to(device)\n",
    "\n",
    "# Count parameters\n",
    "cnn_params = sum(p.numel() for p in cnn_model.parameters())\n",
    "mlp_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\"ðŸ–¼ï¸ CNN ARCHITECTURE\")\n",
    "print(\"=\"*50)\n",
    "print(cnn_model)\n",
    "print(f\"\\nðŸ“Š CNN Parameters: {cnn_params:,}\")\n",
    "print(f\"ðŸ“Š MLP Parameters: {mlp_params:,}\")\n",
    "print(f\"\\nðŸ’¡ CNN has similar capacity but preserves spatial structure!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b27c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "print(\"ðŸ‹ï¸ TRAINING CNN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "cnn_scheduler = optim.lr_scheduler.StepLR(cnn_optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "cnn_history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train_epoch(cnn_model, train_loader, criterion, cnn_optimizer, device)\n",
    "    test_loss, test_acc = evaluate(cnn_model, test_loader, criterion, device)\n",
    "    cnn_scheduler.step()\n",
    "    \n",
    "    cnn_history['train_loss'].append(train_loss)\n",
    "    cnn_history['train_acc'].append(train_acc)\n",
    "    cnn_history['test_loss'].append(test_loss)\n",
    "    cnn_history['test_acc'].append(test_acc)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1:2d}/10] \"\n",
    "          f\"Train: {train_acc:.2f}% | Test: {test_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ CNN Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"ðŸ“Š MLP Test Accuracy: {history['test_acc'][-1]:.2f}%\")\n",
    "print(f\"\\nâœ… CNN outperforms MLP on image data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc976f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Recurrent Neural Networks (RNNs) for Sequences\n",
    "\n",
    "**RNNs** are designed for sequential data (text, time series, audio):\n",
    "- Process one element at a time\n",
    "- Maintain \"hidden state\" (memory) across timesteps\n",
    "- Share weights across time\n",
    "\n",
    "### The RNN Equation:\n",
    "\n",
    "$$h_t = \\tanh(W_{hh} h_{t-1} + W_{xh} x_t + b_h)$$\n",
    "$$y_t = W_{hy} h_t + b_y$$\n",
    "\n",
    "Where:\n",
    "- $x_t$ = input at time t\n",
    "- $h_t$ = hidden state at time t\n",
    "- $y_t$ = output at time t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64625ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN from Scratch - Understanding the internals\n",
    "class RNNCell:\n",
    "    \"\"\"Single RNN cell - processes one timestep\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # Initialize weights with Xavier initialization\n",
    "        self.Wxh = np.random.randn(hidden_size, input_size) * np.sqrt(2.0 / (input_size + hidden_size))\n",
    "        self.Whh = np.random.randn(hidden_size, hidden_size) * np.sqrt(2.0 / (2 * hidden_size))\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        x: input at current timestep (input_size, 1)\n",
    "        h_prev: hidden state from previous timestep (hidden_size, 1)\n",
    "        \"\"\"\n",
    "        # RNN equation: h_t = tanh(Wxh @ x + Whh @ h_prev + b)\n",
    "        h_next = np.tanh(self.Wxh @ x + self.Whh @ h_prev + self.bh)\n",
    "        return h_next\n",
    "\n",
    "# Demonstrate RNN processing a sequence\n",
    "print(\"=\" * 50)\n",
    "print(\"RNN Processing Demonstration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create RNN cell\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "rnn_cell = RNNCell(input_size, hidden_size)\n",
    "\n",
    "# Process a sequence of 5 timesteps\n",
    "sequence_length = 5\n",
    "sequence = [np.random.randn(input_size, 1) for _ in range(sequence_length)]\n",
    "\n",
    "# Initialize hidden state\n",
    "h = np.zeros((hidden_size, 1))\n",
    "\n",
    "print(f\"\\nProcessing sequence of length {sequence_length}\")\n",
    "print(f\"Input size: {input_size}, Hidden size: {hidden_size}\")\n",
    "\n",
    "# Process each timestep\n",
    "hidden_states = []\n",
    "for t, x in enumerate(sequence):\n",
    "    h = rnn_cell.forward(x, h)\n",
    "    hidden_states.append(h)\n",
    "    print(f\"  Timestep {t}: h shape = {h.shape}, h mean = {h.mean():.4f}\")\n",
    "\n",
    "print(f\"\\nâœ“ Final hidden state captures information from all {sequence_length} timesteps!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b41ab3d",
   "metadata": {},
   "source": [
    "### The Vanishing Gradient Problem\n",
    "\n",
    "Standard RNNs suffer from **vanishing gradients**:\n",
    "- Gradients shrink exponentially over long sequences\n",
    "- Network \"forgets\" early information\n",
    "- Solution: **LSTM** (Long Short-Term Memory) and **GRU** (Gated Recurrent Unit)\n",
    "\n",
    "### LSTM Architecture\n",
    "\n",
    "LSTMs add **gates** to control information flow:\n",
    "1. **Forget Gate**: What to throw away from cell state\n",
    "2. **Input Gate**: What new information to store\n",
    "3. **Output Gate**: What to output based on cell state\n",
    "\n",
    "$$f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$$ (forget gate)\n",
    "$$i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$$ (input gate)  \n",
    "$$\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$$ (candidate)\n",
    "$$C_t = f_t * C_{t-1} + i_t * \\tilde{C}_t$$ (cell state)\n",
    "$$o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$$ (output gate)\n",
    "$$h_t = o_t * \\tanh(C_t)$$ (hidden state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e12981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM in PyTorch - Sequence Classification Example\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.2):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,  # (batch, seq, feature)\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, input_size)\n",
    "        \n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        # out: (batch, seq_len, hidden_size)\n",
    "        # hn: final hidden state\n",
    "        # cn: final cell state\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Take the last timestep output\n",
    "        out = out[:, -1, :]  # (batch, hidden_size)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Create synthetic sequence data\n",
    "print(\"=\" * 50)\n",
    "print(\"LSTM Sequence Classification Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate synthetic sequences (e.g., time series)\n",
    "def generate_sequence_data(n_samples, seq_length, n_features, n_classes):\n",
    "    X = np.zeros((n_samples, seq_length, n_features))\n",
    "    y = np.zeros(n_samples, dtype=np.int64)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        label = np.random.randint(0, n_classes)\n",
    "        y[i] = label\n",
    "        \n",
    "        # Create different patterns for each class\n",
    "        t = np.linspace(0, 4*np.pi, seq_length)\n",
    "        for f in range(n_features):\n",
    "            if label == 0:\n",
    "                X[i, :, f] = np.sin(t * (f+1)) + np.random.randn(seq_length) * 0.1\n",
    "            elif label == 1:\n",
    "                X[i, :, f] = np.cos(t * (f+1)) + np.random.randn(seq_length) * 0.1\n",
    "            else:\n",
    "                X[i, :, f] = np.sin(t * (f+1)) * np.exp(-t/10) + np.random.randn(seq_length) * 0.1\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generate data\n",
    "n_samples, seq_length, n_features, n_classes = 1000, 50, 5, 3\n",
    "X, y = generate_sequence_data(n_samples, seq_length, n_features, n_classes)\n",
    "\n",
    "# Split and convert to tensors\n",
    "X_train, X_test = X[:800], X[800:]\n",
    "y_train, y_test = y[:800], y[800:]\n",
    "\n",
    "X_train = torch.FloatTensor(X_train).to(device)\n",
    "X_test = torch.FloatTensor(X_test).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "y_test = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "# Create model\n",
    "lstm_model = LSTMClassifier(\n",
    "    input_size=n_features,\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    num_classes=n_classes,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(lstm_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")\n",
    "\n",
    "# Train\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "lstm_model.train()\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/20], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = lstm_model(X_test)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    accuracy = (predicted == y_test).sum().item() / len(y_test)\n",
    "    print(f\"\\nâœ“ Test Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd59828c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Regularization Techniques\n",
    "\n",
    "Regularization prevents **overfitting** - when model performs well on training but poorly on test data.\n",
    "\n",
    "### Key Techniques:\n",
    "1. **Dropout**: Randomly zero out neurons during training\n",
    "2. **Batch Normalization**: Normalize layer inputs\n",
    "3. **Weight Decay (L2)**: Penalize large weights\n",
    "4. **Data Augmentation**: Create variations of training data\n",
    "5. **Early Stopping**: Stop when validation loss increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Regularization Demo\n",
    "print(\"=\" * 60)\n",
    "print(\"Regularization Techniques Demonstration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. DROPOUT\n",
    "print(\"\\n1. DROPOUT\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "class DropoutDemo(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)  # p = probability of zeroing\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Only active during training!\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "dropout_model = DropoutDemo(dropout_rate=0.5)\n",
    "test_input = torch.randn(1, 100)\n",
    "\n",
    "# Training mode - dropout active\n",
    "dropout_model.train()\n",
    "outputs_train = [dropout_model(test_input).sum().item() for _ in range(5)]\n",
    "print(f\"Training mode outputs (vary due to dropout): {[f'{x:.2f}' for x in outputs_train]}\")\n",
    "\n",
    "# Eval mode - dropout disabled\n",
    "dropout_model.eval()\n",
    "outputs_eval = [dropout_model(test_input).sum().item() for _ in range(5)]\n",
    "print(f\"Eval mode outputs (consistent): {[f'{x:.2f}' for x in outputs_eval]}\")\n",
    "\n",
    "# 2. BATCH NORMALIZATION\n",
    "print(\"\\n2. BATCH NORMALIZATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "class BatchNormDemo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.bn1 = nn.BatchNorm1d(50)  # Normalizes each feature across batch\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)  # Normalize: (x - mean) / std, then scale and shift\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "bn_model = BatchNormDemo()\n",
    "batch_input = torch.randn(32, 100)  # Batch of 32 samples\n",
    "\n",
    "bn_model.train()\n",
    "output = bn_model(batch_input)\n",
    "print(f\"BatchNorm output shape: {output.shape}\")\n",
    "print(f\"BatchNorm running_mean shape: {bn_model.bn1.running_mean.shape}\")\n",
    "print(\"âœ“ BatchNorm tracks running statistics during training\")\n",
    "\n",
    "# 3. WEIGHT DECAY (L2 REGULARIZATION)\n",
    "print(\"\\n3. WEIGHT DECAY (L2 Regularization)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# L2 regularization is built into the optimizer\n",
    "optimizer_with_wd = optim.Adam(bn_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "print(\"optimizer = Adam(params, lr=0.001, weight_decay=1e-4)\")\n",
    "print(\"This adds Î» * ||w||Â² to the loss, penalizing large weights\")\n",
    "\n",
    "# 4. DATA AUGMENTATION\n",
    "print(\"\\n4. DATA AUGMENTATION (for images)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),       # 50% chance to flip\n",
    "    transforms.RandomRotation(degrees=10),         # Rotate Â±10 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Shift up to 10%\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),       # Vary color\n",
    "    transforms.RandomCrop(28, padding=4),          # Random crop with padding\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "print(\"Common image augmentations:\")\n",
    "print(\"  - RandomHorizontalFlip\")\n",
    "print(\"  - RandomRotation\")\n",
    "print(\"  - RandomAffine (shift, scale, shear)\")\n",
    "print(\"  - ColorJitter\")\n",
    "print(\"  - RandomCrop\")\n",
    "\n",
    "# 5. EARLY STOPPING\n",
    "print(\"\\n5. EARLY STOPPING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Stop training when validation loss stops improving.\"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.should_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        return self.should_stop\n",
    "\n",
    "# Demo\n",
    "early_stopper = EarlyStopping(patience=3)\n",
    "fake_losses = [0.5, 0.4, 0.35, 0.36, 0.37, 0.38, 0.39]\n",
    "for epoch, loss in enumerate(fake_losses):\n",
    "    stopped = early_stopper(loss)\n",
    "    print(f\"Epoch {epoch+1}: loss={loss:.2f}, counter={early_stopper.counter}, stop={stopped}\")\n",
    "\n",
    "print(\"\\nâœ“ Early stopping prevents overfitting by stopping at optimal point!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075c86f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Advanced Deep Learning ðŸš€\n",
    "\n",
    "Now we enter the advanced territory that powers modern AI systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d2834",
   "metadata": {},
   "source": [
    "## Section 10: The Transformer Architecture - The Foundation of Modern AI\n",
    "\n",
    "**Transformers** revolutionized deep learning (2017 \"Attention Is All You Need\" paper).\n",
    "\n",
    "### Why Transformers Beat RNNs:\n",
    "1. **Parallel Processing**: Process all tokens simultaneously (not sequentially)\n",
    "2. **Long-Range Dependencies**: Direct connections between any two positions\n",
    "3. **Scalability**: Train on massive datasets with thousands of GPUs\n",
    "\n",
    "### Key Components:\n",
    "1. **Self-Attention**: Each token attends to all other tokens\n",
    "2. **Multi-Head Attention**: Multiple parallel attention mechanisms\n",
    "3. **Positional Encoding**: Inject position information\n",
    "4. **Feed-Forward Networks**: Process each position independently\n",
    "\n",
    "### Self-Attention Mechanism:\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "Where:\n",
    "- Q (Query): \"What am I looking for?\"\n",
    "- K (Key): \"What do I contain?\"\n",
    "- V (Value): \"What information do I provide?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Attention from Scratch\n",
    "print(\"=\" * 60)\n",
    "print(\"Self-Attention Mechanism - Step by Step\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def self_attention(X, W_q, W_k, W_v):\n",
    "    \"\"\"\n",
    "    Compute self-attention\n",
    "    \n",
    "    X: Input embeddings (seq_len, d_model)\n",
    "    W_q, W_k, W_v: Weight matrices for Q, K, V projections\n",
    "    \"\"\"\n",
    "    # Step 1: Create Query, Key, Value projections\n",
    "    Q = X @ W_q  # (seq_len, d_k)\n",
    "    K = X @ W_k  # (seq_len, d_k)\n",
    "    V = X @ W_v  # (seq_len, d_v)\n",
    "    \n",
    "    d_k = K.shape[-1]\n",
    "    \n",
    "    # Step 2: Compute attention scores\n",
    "    # Each query attends to all keys\n",
    "    scores = Q @ K.T  # (seq_len, seq_len)\n",
    "    \n",
    "    # Step 3: Scale by sqrt(d_k) for stable gradients\n",
    "    scores = scores / np.sqrt(d_k)\n",
    "    \n",
    "    # Step 4: Apply softmax to get attention weights\n",
    "    # Each row sums to 1\n",
    "    attention_weights = np.exp(scores) / np.exp(scores).sum(axis=-1, keepdims=True)\n",
    "    \n",
    "    # Step 5: Weighted sum of values\n",
    "    output = attention_weights @ V\n",
    "    \n",
    "    return output, attention_weights\n",
    "\n",
    "# Example with a short sequence\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate a sequence of 4 tokens, each with 8-dimensional embedding\n",
    "seq_len = 4\n",
    "d_model = 8\n",
    "d_k = d_v = 4\n",
    "\n",
    "# Input: 4 token embeddings\n",
    "X = np.random.randn(seq_len, d_model)\n",
    "print(f\"\\nInput X shape: {X.shape} (seq_len={seq_len}, d_model={d_model})\")\n",
    "\n",
    "# Weight matrices\n",
    "W_q = np.random.randn(d_model, d_k) * 0.1\n",
    "W_k = np.random.randn(d_model, d_k) * 0.1\n",
    "W_v = np.random.randn(d_model, d_v) * 0.1\n",
    "\n",
    "# Compute attention\n",
    "output, attention_weights = self_attention(X, W_q, W_k, W_v)\n",
    "\n",
    "print(f\"\\nAttention Weights (each row shows how much token attends to others):\")\n",
    "print(f\"Token\\\\To | Token 0 | Token 1 | Token 2 | Token 3\")\n",
    "print(\"-\" * 55)\n",
    "for i in range(seq_len):\n",
    "    weights_str = \" | \".join([f\"{w:.3f}\" for w in attention_weights[i]])\n",
    "    print(f\"Token {i}  | {weights_str}\")\n",
    "\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n",
    "print(f\"\\nâœ“ Each token's output is a weighted combination of all value vectors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Head Attention in PyTorch\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention allows the model to attend to information\n",
    "    from different representation subspaces at different positions.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        # Linear projections for Q, K, V and output\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, d_k)\"\"\"\n",
    "        # x: (batch, seq_len, d_model)\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.d_k)\n",
    "        # Transpose to (batch, num_heads, seq_len, d_k)\n",
    "        return x.transpose(1, 2)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        # Linear projections\n",
    "        Q = self.W_q(query)  # (batch, seq_len, d_model)\n",
    "        K = self.W_k(key)\n",
    "        V = self.W_v(value)\n",
    "        \n",
    "        # Split into multiple heads\n",
    "        Q = self.split_heads(Q, batch_size)  # (batch, num_heads, seq_len, d_k)\n",
    "        K = self.split_heads(K, batch_size)\n",
    "        V = self.split_heads(V, batch_size)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask (for decoder self-attention)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        # Softmax and weighted sum\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_output = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        # Concatenate heads\n",
    "        # (batch, num_heads, seq_len, d_k) -> (batch, seq_len, d_model)\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous()\n",
    "        attention_output = attention_output.view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        # Final linear projection\n",
    "        output = self.W_o(attention_output)\n",
    "        \n",
    "        return output, attention_weights\n",
    "\n",
    "# Demo Multi-Head Attention\n",
    "print(\"=\" * 60)\n",
    "print(\"Multi-Head Attention Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "d_model = 64\n",
    "num_heads = 8\n",
    "\n",
    "mha = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "# Random input (batch of 2 sequences, each 10 tokens, 64-dim embeddings)\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# Self-attention: query, key, value are all the same\n",
    "output, attn_weights = mha(x, x, x)\n",
    "\n",
    "print(f\"\\nInput shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Attention weights shape: {attn_weights.shape}\")\n",
    "print(f\"  â†’ {batch_size} batches Ã— {num_heads} heads Ã— {seq_len} queries Ã— {seq_len} keys\")\n",
    "print(f\"\\nâœ“ Each head can learn different attention patterns!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299732af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Transformer Encoder Block\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single Transformer encoder block.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Multi-Head Self-Attention\n",
    "    2. Add & Normalize (residual connection + LayerNorm)\n",
    "    3. Feed-Forward Network (2 linear layers with ReLU)\n",
    "    4. Add & Normalize\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multi-head attention\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # Self-attention with residual connection\n",
    "        attn_output, _ = self.attention(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-forward with residual connection\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Add positional information to embeddings using sine and cosine functions.\n",
    "    \n",
    "    PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "    PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create positional encoding matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd indices\n",
    "        \n",
    "        pe = pe.unsqueeze(0)  # Add batch dimension\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to input embeddings\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete Transformer Encoder for sequence classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, \n",
    "                 num_classes, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        \n",
    "        # Stack of encoder blocks\n",
    "        self.encoder_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlock(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # x: (batch, seq_len) - token indices\n",
    "        \n",
    "        # Token embeddings + positional encoding\n",
    "        x = self.embedding(x) * np.sqrt(self.d_model)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Pass through encoder blocks\n",
    "        for encoder_block in self.encoder_blocks:\n",
    "            x = encoder_block(x, mask)\n",
    "        \n",
    "        # Global average pooling and classification\n",
    "        x = x.mean(dim=1)  # (batch, d_model)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create and test the Transformer Encoder\n",
    "print(\"=\" * 60)\n",
    "print(\"Complete Transformer Encoder\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "transformer = TransformerEncoder(\n",
    "    vocab_size=10000,\n",
    "    d_model=128,\n",
    "    num_heads=8,\n",
    "    num_layers=4,\n",
    "    d_ff=512,\n",
    "    num_classes=5,\n",
    "    max_len=512,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nArchitecture:\")\n",
    "print(f\"  - Vocab size: 10,000\")\n",
    "print(f\"  - Embedding dim (d_model): 128\")\n",
    "print(f\"  - Attention heads: 8\")\n",
    "print(f\"  - Encoder layers: 4\")\n",
    "print(f\"  - FFN hidden dim: 512\")\n",
    "print(f\"  - Output classes: 5\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in transformer.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "batch = torch.randint(0, 10000, (4, 100)).to(device)  # 4 sequences, 100 tokens each\n",
    "output = transformer(batch)\n",
    "print(f\"\\nInput shape: {batch.shape} (batch=4, seq_len=100)\")\n",
    "print(f\"Output shape: {output.shape} (batch=4, num_classes=5)\")\n",
    "print(\"\\nâœ“ Transformer encoder successfully built from scratch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b14d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 11: Generative Adversarial Networks (GANs)\n",
    "\n",
    "**GANs** consist of two networks competing against each other:\n",
    "1. **Generator (G)**: Creates fake samples to fool the discriminator\n",
    "2. **Discriminator (D)**: Tries to distinguish real from fake samples\n",
    "\n",
    "### The Minimax Game:\n",
    "\n",
    "$$\\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))]$$\n",
    "\n",
    "### Training Process:\n",
    "1. Train D to maximize correct classifications (real vs fake)\n",
    "2. Train G to minimize D's ability to detect fakes\n",
    "3. Alternate between steps 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eddc0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN for MNIST Generation\n",
    "print(\"=\" * 60)\n",
    "print(\"Generative Adversarial Network (GAN) - MNIST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Latent dimension (noise vector size)\n",
    "latent_dim = 100\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator: Maps random noise to realistic images.\n",
    "    noise (latent_dim) -> image (1, 28, 28)\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Input: latent_dim\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            \n",
    "            nn.Linear(1024, 28*28),\n",
    "            nn.Tanh()  # Output in [-1, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img.view(-1, 1, 28, 28)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator: Classifies images as real or fake.\n",
    "    image (1, 28, 28) -> probability (real or fake)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # Output probability\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "\n",
    "# Optimizers (separate for G and D)\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Load MNIST with normalization to [-1, 1] to match Tanh output\n",
    "gan_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "gan_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=gan_transform)\n",
    "gan_loader = DataLoader(gan_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nTraining GAN...\")\n",
    "n_epochs = 5  # Reduced for demo (use 50+ for good results)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (real_imgs, _) in enumerate(gan_loader):\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        \n",
    "        # Labels\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # ---------------------\n",
    "        # Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Loss on real images\n",
    "        real_output = discriminator(real_imgs)\n",
    "        d_loss_real = adversarial_loss(real_output, real_labels)\n",
    "        \n",
    "        # Loss on fake images\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        fake_output = discriminator(fake_imgs.detach())  # Detach to not train G\n",
    "        d_loss_fake = adversarial_loss(fake_output, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # ---------------------\n",
    "        # Train Generator\n",
    "        # ---------------------\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Generate fake images and try to fool discriminator\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        fake_output = discriminator(fake_imgs)\n",
    "        \n",
    "        # Generator wants discriminator to think fakes are real\n",
    "        g_loss = adversarial_loss(fake_output, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}] D_loss: {d_loss.item():.4f} G_loss: {g_loss.item():.4f}\")\n",
    "\n",
    "print(\"\\nâœ“ GAN training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Generated Images\n",
    "print(\"Generated Images from GAN:\")\n",
    "\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate images from random noise\n",
    "    z = torch.randn(16, latent_dim).to(device)\n",
    "    generated_imgs = generator(z)\n",
    "    generated_imgs = generated_imgs.cpu()\n",
    "\n",
    "# Plot generated images\n",
    "fig, axes = plt.subplots(2, 8, figsize=(14, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Denormalize from [-1, 1] to [0, 1]\n",
    "    img = (generated_imgs[i].squeeze() + 1) / 2\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('GAN Generated MNIST Digits (5 epochs training)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ With more training epochs (50+), the generated digits will look much more realistic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dfab30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 12: Transfer Learning - Standing on the Shoulders of Giants\n",
    "\n",
    "**Transfer Learning** uses pre-trained models as starting points:\n",
    "- Leverage knowledge from models trained on millions of images\n",
    "- Fine-tune for your specific task with much less data\n",
    "- Often achieves better results than training from scratch\n",
    "\n",
    "### Common Strategies:\n",
    "1. **Feature Extraction**: Freeze pre-trained layers, only train new classifier\n",
    "2. **Fine-tuning**: Unfreeze some layers and train with low learning rate\n",
    "3. **Full Fine-tuning**: Unfreeze all layers (requires more data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning with Pre-trained ResNet\n",
    "print(\"=\" * 60)\n",
    "print(\"Transfer Learning with ResNet-18\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "# Load pre-trained ResNet-18 (trained on ImageNet - 1000 classes, millions of images)\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "print(\"\\nPre-trained ResNet-18 loaded!\")\n",
    "print(f\"Original output classes: 1000 (ImageNet)\")\n",
    "\n",
    "# Examine the model structure\n",
    "print(\"\\n--- Last few layers ---\")\n",
    "print(f\"avgpool: {resnet.avgpool}\")\n",
    "print(f\"fc: {resnet.fc}\")\n",
    "\n",
    "# Strategy 1: Feature Extraction (freeze all layers except final classifier)\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"Strategy 1: Feature Extraction\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Freeze all parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer\n",
    "num_features = resnet.fc.in_features  # Get input features of original fc layer\n",
    "num_classes = 10  # Our new number of classes\n",
    "\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "\n",
    "# Only the new fc layer will be trained\n",
    "trainable_params = sum(p.numel() for p in resnet.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in resnet.parameters())\n",
    "print(f\"\\nTrainable parameters: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.1f}%)\")\n",
    "\n",
    "# Strategy 2: Fine-tuning (unfreeze last few layers)\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"Strategy 2: Fine-tuning\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Reload model\n",
    "resnet_ft = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze early layers (feature extractors)\n",
    "layers_to_freeze = ['conv1', 'bn1', 'layer1', 'layer2']\n",
    "for name, param in resnet_ft.named_parameters():\n",
    "    if any(layer in name for layer in layers_to_freeze):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Replace final layer\n",
    "resnet_ft.fc = nn.Linear(resnet_ft.fc.in_features, num_classes)\n",
    "\n",
    "trainable_ft = sum(p.numel() for p in resnet_ft.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_ft:,} / {total_params:,} ({100*trainable_ft/total_params:.1f}%)\")\n",
    "\n",
    "# Show which layers are trainable\n",
    "print(\"\\nTrainable layers:\")\n",
    "for name, param in resnet_ft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if 'layer3' in name or 'layer4' in name or 'fc' in name:\n",
    "            print(f\"  âœ“ {name}\")\n",
    "            break\n",
    "print(\"  âœ“ layer3.*, layer4.*, fc.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba76532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Transfer Learning Pipeline\n",
    "print(\"=\" * 60)\n",
    "print(\"Complete Transfer Learning Training Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class TransferLearningModel:\n",
    "    \"\"\"\n",
    "    A complete transfer learning pipeline with best practices.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model_name='resnet18', num_classes=10, \n",
    "                 freeze_base=True, device='cpu'):\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load pre-trained model\n",
    "        if base_model_name == 'resnet18':\n",
    "            self.model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "            num_features = self.model.fc.in_features\n",
    "        elif base_model_name == 'resnet50':\n",
    "            self.model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "            num_features = self.model.fc.in_features\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {base_model_name}\")\n",
    "        \n",
    "        # Freeze base model if specified\n",
    "        if freeze_base:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.model = self.model.to(device)\n",
    "    \n",
    "    def get_transforms(self, train=True):\n",
    "        \"\"\"Get appropriate transforms for training or evaluation.\"\"\"\n",
    "        if train:\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],  # ImageNet means\n",
    "                    std=[0.229, 0.224, 0.225]    # ImageNet stds\n",
    "                )\n",
    "            ])\n",
    "        else:\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "    def train_epoch(self, train_loader, optimizer, criterion):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        return total_loss / len(train_loader), 100 * correct / total\n",
    "    \n",
    "    def evaluate(self, test_loader, criterion):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        return total_loss / len(test_loader), 100 * correct / total\n",
    "    \n",
    "    def unfreeze_layers(self, num_layers=2):\n",
    "        \"\"\"Unfreeze the last n layer groups for fine-tuning.\"\"\"\n",
    "        # Get all layer groups\n",
    "        layer_groups = ['layer4', 'layer3', 'layer2', 'layer1']\n",
    "        layers_to_unfreeze = layer_groups[:num_layers]\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if any(layer in name for layer in layers_to_unfreeze):\n",
    "                param.requires_grad = True\n",
    "\n",
    "# Demo\n",
    "print(\"\\nCreating Transfer Learning model...\")\n",
    "tl_model = TransferLearningModel(\n",
    "    base_model_name='resnet18',\n",
    "    num_classes=10,\n",
    "    freeze_base=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Show trainable parameters\n",
    "trainable = sum(p.numel() for p in tl_model.model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in tl_model.model.parameters())\n",
    "print(f\"\\nâœ“ Model created with feature extraction (frozen base)\")\n",
    "print(f\"  Trainable: {trainable:,} / {total:,} parameters\")\n",
    "\n",
    "# Unfreeze for fine-tuning\n",
    "print(\"\\nUnfreezing layer4 and layer3 for fine-tuning...\")\n",
    "tl_model.unfreeze_layers(num_layers=2)\n",
    "\n",
    "trainable = sum(p.numel() for p in tl_model.model.parameters() if p.requires_grad)\n",
    "print(f\"âœ“ Trainable: {trainable:,} / {total:,} parameters\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Training Tips:\")\n",
    "print(\"  1. Start with frozen base, train classifier first\")\n",
    "print(\"  2. Then unfreeze top layers with lower LR\")\n",
    "print(\"  3. Use different LRs: new layers (1e-3), unfrozen layers (1e-5)\")\n",
    "print(\"  4. Always use ImageNet normalization for pre-trained models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b02a845",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 13: Advanced Training Techniques\n",
    "\n",
    "These techniques are used in state-of-the-art deep learning systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edf0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Training Techniques\n",
    "print(\"=\" * 60)\n",
    "print(\"Advanced Training Techniques\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. LEARNING RATE SCHEDULING\n",
    "print(\"\\n1. LEARNING RATE SCHEDULING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create a dummy model for demonstration\n",
    "dummy_model = nn.Linear(10, 2)\n",
    "optimizer = optim.Adam(dummy_model.parameters(), lr=0.001)\n",
    "\n",
    "# Different schedulers\n",
    "print(\"Common LR Schedulers:\")\n",
    "\n",
    "# Step decay\n",
    "step_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "print(f\"  StepLR: Multiply LR by 0.1 every 10 epochs\")\n",
    "\n",
    "# Cosine annealing\n",
    "cosine_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "print(f\"  CosineAnnealingLR: Smoothly decrease LR following cosine curve\")\n",
    "\n",
    "# One cycle (very effective for fast training)\n",
    "# one_cycle = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, total_steps=100)\n",
    "print(f\"  OneCycleLR: Increase then decrease LR (super-convergence)\")\n",
    "\n",
    "# Reduce on plateau\n",
    "plateau_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "print(f\"  ReduceLROnPlateau: Reduce when validation loss stops improving\")\n",
    "\n",
    "# Visualize LR schedules\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 3))\n",
    "\n",
    "# StepLR\n",
    "lrs = []\n",
    "opt_temp = optim.Adam([torch.zeros(1, requires_grad=True)], lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(opt_temp, step_size=10, gamma=0.5)\n",
    "for _ in range(50):\n",
    "    lrs.append(opt_temp.param_groups[0]['lr'])\n",
    "    scheduler.step()\n",
    "axes[0].plot(lrs)\n",
    "axes[0].set_title('StepLR (step=10, Î³=0.5)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Learning Rate')\n",
    "\n",
    "# CosineAnnealingLR\n",
    "lrs = []\n",
    "opt_temp = optim.Adam([torch.zeros(1, requires_grad=True)], lr=0.001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(opt_temp, T_max=50)\n",
    "for _ in range(50):\n",
    "    lrs.append(opt_temp.param_groups[0]['lr'])\n",
    "    scheduler.step()\n",
    "axes[1].plot(lrs)\n",
    "axes[1].set_title('CosineAnnealingLR (T_max=50)')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "\n",
    "# Warmup + CosineAnnealing\n",
    "lrs = []\n",
    "warmup_epochs = 5\n",
    "total_epochs = 50\n",
    "for epoch in range(total_epochs):\n",
    "    if epoch < warmup_epochs:\n",
    "        lr = 0.001 * (epoch + 1) / warmup_epochs\n",
    "    else:\n",
    "        lr = 0.001 * 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (total_epochs - warmup_epochs)))\n",
    "    lrs.append(lr)\n",
    "axes[2].plot(lrs)\n",
    "axes[2].set_title('Warmup + CosineAnnealing')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. GRADIENT ACCUMULATION\n",
    "print(\"\\n2. GRADIENT ACCUMULATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def train_with_gradient_accumulation(model, loader, optimizer, criterion, \n",
    "                                     accumulation_steps=4):\n",
    "    \"\"\"\n",
    "    Simulate larger batch size by accumulating gradients.\n",
    "    Effective batch size = batch_size Ã— accumulation_steps\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets) / accumulation_steps  # Scale loss\n",
    "        loss.backward()  # Accumulate gradients\n",
    "        \n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()  # Update weights\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Gradient Accumulation allows simulating larger batches:\")\n",
    "print(\"  batch_size=16, accumulation_steps=4 â†’ effective_batch=64\")\n",
    "print(\"  Useful when GPU memory is limited\")\n",
    "\n",
    "# 3. MIXED PRECISION TRAINING\n",
    "print(\"\\n3. MIXED PRECISION TRAINING (AMP)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    \n",
    "    def train_with_mixed_precision():\n",
    "        \"\"\"\n",
    "        Use FP16 for forward/backward pass, FP32 for weight updates.\n",
    "        Reduces memory usage and can speed up training 2-3x.\n",
    "        \"\"\"\n",
    "        scaler = GradScaler()  # Handles loss scaling\n",
    "        \n",
    "        for inputs, targets in loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass in FP16\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass with scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "    \n",
    "    print(\"âœ“ Mixed Precision available on CUDA\")\n",
    "else:\n",
    "    print(\"âš  Mixed Precision requires CUDA GPU\")\n",
    "\n",
    "print(\"\\nMixed Precision Benefits:\")\n",
    "print(\"  - 2-3x faster training\")\n",
    "print(\"  - 50% less GPU memory\")\n",
    "print(\"  - Automatic loss scaling prevents underflow\")\n",
    "\n",
    "# 4. GRADIENT CLIPPING\n",
    "print(\"\\n4. GRADIENT CLIPPING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"Prevents exploding gradients (especially in RNNs):\")\n",
    "print(\"  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\")\n",
    "print(\"  torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=0.5)\")\n",
    "\n",
    "# 5. LABEL SMOOTHING\n",
    "print(\"\\n5. LABEL SMOOTHING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Instead of hard labels (0, 1), use soft labels (0.1, 0.9).\n",
    "    Prevents overconfidence and improves generalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Create soft labels\n",
    "        with torch.no_grad():\n",
    "            soft_target = torch.full_like(pred, self.smoothing / (self.num_classes - 1))\n",
    "            soft_target.scatter_(1, target.unsqueeze(1), 1.0 - self.smoothing)\n",
    "        \n",
    "        # KL divergence loss\n",
    "        log_probs = F.log_softmax(pred, dim=-1)\n",
    "        loss = -(soft_target * log_probs).sum(dim=-1).mean()\n",
    "        return loss\n",
    "\n",
    "# Demo\n",
    "smooth_criterion = LabelSmoothingLoss(num_classes=10, smoothing=0.1)\n",
    "print(f\"Label Smoothing: soft targets instead of one-hot\")\n",
    "print(f\"  Hard: [0, 0, 1, 0, 0] â†’ Soft: [0.025, 0.025, 0.9, 0.025, 0.025]\")\n",
    "\n",
    "print(\"\\nâœ“ These techniques are used in production ML systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae6c673",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 14: AutoEncoders & Variational AutoEncoders (VAE)\n",
    "\n",
    "**AutoEncoders** learn compressed representations of data:\n",
    "- **Encoder**: Compress input to latent space\n",
    "- **Decoder**: Reconstruct input from latent space\n",
    "\n",
    "**VAE** adds probabilistic component - learns a distribution in latent space:\n",
    "- Enables generation of new samples\n",
    "- Foundation for many generative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2184824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variational AutoEncoder (VAE)\n",
    "print(\"=\" * 60)\n",
    "print(\"Variational AutoEncoder (VAE)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational AutoEncoder for MNIST.\n",
    "    \n",
    "    Key difference from regular AutoEncoder:\n",
    "    - Encoder outputs mean (Î¼) and log-variance (log ÏƒÂ²) of latent distribution\n",
    "    - Sample from this distribution using reparameterization trick\n",
    "    - Loss = Reconstruction Loss + KL Divergence\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Latent space parameters\n",
    "        self.fc_mu = nn.Linear(hidden_dim // 2, latent_dim)      # Mean\n",
    "        self.fc_logvar = nn.Linear(hidden_dim // 2, latent_dim)  # Log variance\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # Output in [0, 1]\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent distribution parameters.\"\"\"\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick: z = Î¼ + Ïƒ * Îµ\n",
    "        This allows gradients to flow through sampling.\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)  # Ïƒ = exp(0.5 * log(ÏƒÂ²))\n",
    "        eps = torch.randn_like(std)     # Îµ ~ N(0, 1)\n",
    "        return mu + std * eps\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode latent vector to reconstruction.\"\"\"\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstruction = self.decode(z)\n",
    "        return reconstruction, mu, logvar\n",
    "\n",
    "\n",
    "def vae_loss(reconstruction, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    VAE Loss = Reconstruction Loss + KL Divergence\n",
    "    \n",
    "    Reconstruction: How well did we recreate the input?\n",
    "    KL Divergence: How close is the latent distribution to N(0, 1)?\n",
    "    \"\"\"\n",
    "    # Reconstruction loss (binary cross-entropy)\n",
    "    recon_loss = F.binary_cross_entropy(reconstruction, x, reduction='sum')\n",
    "    \n",
    "    # KL Divergence: D_KL(q(z|x) || p(z)) where p(z) = N(0, 1)\n",
    "    # Closed-form solution: -0.5 * Î£(1 + log(ÏƒÂ²) - Î¼Â² - ÏƒÂ²)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return recon_loss + kl_loss\n",
    "\n",
    "\n",
    "# Train VAE\n",
    "vae = VAE(input_dim=784, hidden_dim=400, latent_dim=20).to(device)\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "print(f\"\\nVAE Architecture:\")\n",
    "print(f\"  Input: 784 (28Ã—28 image)\")\n",
    "print(f\"  Hidden: 400 â†’ 200\")\n",
    "print(f\"  Latent: 20 dimensions\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in vae.parameters()):,}\")\n",
    "\n",
    "# Load MNIST for VAE (normalized to [0, 1])\n",
    "vae_transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Already in [0, 1]\n",
    "])\n",
    "vae_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=vae_transform)\n",
    "vae_loader = DataLoader(vae_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "print(\"\\nTraining VAE...\")\n",
    "vae.train()\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(vae_loader):\n",
    "        data = data.view(-1, 784).to(device)\n",
    "        \n",
    "        vae_optimizer.zero_grad()\n",
    "        reconstruction, mu, logvar = vae(data)\n",
    "        loss = vae_loss(reconstruction, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        vae_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(vae_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/5], Loss: {avg_loss:.2f}\")\n",
    "\n",
    "print(\"\\nâœ“ VAE training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE: Reconstruction and Generation\n",
    "print(\"VAE Results:\")\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    # 1. Reconstruction: Encode then decode\n",
    "    test_data, _ = next(iter(vae_loader))\n",
    "    test_data = test_data[:8].view(-1, 784).to(device)\n",
    "    reconstructed, _, _ = vae(test_data)\n",
    "    \n",
    "    # 2. Generation: Sample from latent space\n",
    "    z_samples = torch.randn(8, 20).to(device)  # Sample from N(0, 1)\n",
    "    generated = vae.decode(z_samples)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(3, 8, figsize=(14, 5))\n",
    "\n",
    "# Original images\n",
    "for i in range(8):\n",
    "    axes[0, i].imshow(test_data[i].cpu().view(28, 28), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "axes[0, 0].set_ylabel('Original', fontsize=12)\n",
    "\n",
    "# Reconstructed images\n",
    "for i in range(8):\n",
    "    axes[1, i].imshow(reconstructed[i].cpu().view(28, 28), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "axes[1, 0].set_ylabel('Reconstructed', fontsize=12)\n",
    "\n",
    "# Generated images\n",
    "for i in range(8):\n",
    "    axes[2, i].imshow(generated[i].cpu().view(28, 28), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "axes[2, 0].set_ylabel('Generated', fontsize=12)\n",
    "\n",
    "plt.suptitle('VAE: Reconstruction & Generation', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Latent space interpolation\n",
    "print(\"\\nLatent Space Interpolation:\")\n",
    "with torch.no_grad():\n",
    "    # Encode two images\n",
    "    img1 = test_data[0:1]\n",
    "    img2 = test_data[7:8]\n",
    "    \n",
    "    z1, _ = vae.encode(img1)\n",
    "    z2, _ = vae.encode(img2)\n",
    "    \n",
    "    # Interpolate in latent space\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(14, 2))\n",
    "    for i, alpha in enumerate(np.linspace(0, 1, 10)):\n",
    "        z_interp = (1 - alpha) * z1 + alpha * z2\n",
    "        img_interp = vae.decode(z_interp)\n",
    "        axes[i].imshow(img_interp.cpu().view(28, 28), cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'{alpha:.1f}')\n",
    "    \n",
    "    plt.suptitle('Interpolation in Latent Space', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nâœ“ VAE enables smooth interpolation between images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bff72c4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 15: Model Deployment & Production Best Practices\n",
    "\n",
    "Taking models from notebooks to production requires additional considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf61cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Deployment Best Practices\n",
    "print(\"=\" * 60)\n",
    "print(\"Model Deployment & Production Best Practices\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. SAVING AND LOADING MODELS\n",
    "print(\"\\n1. SAVING AND LOADING MODELS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create a sample model\n",
    "sample_model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "# Method 1: Save entire model (includes architecture)\n",
    "# torch.save(sample_model, 'model_complete.pth')\n",
    "# loaded_model = torch.load('model_complete.pth')\n",
    "\n",
    "# Method 2: Save state_dict only (RECOMMENDED)\n",
    "print(\"Recommended: Save state_dict (weights only)\")\n",
    "print(\"  torch.save(model.state_dict(), 'model_weights.pth')\")\n",
    "print(\"  model.load_state_dict(torch.load('model_weights.pth'))\")\n",
    "\n",
    "# Save checkpoint with training state\n",
    "checkpoint = {\n",
    "    'epoch': 10,\n",
    "    'model_state_dict': sample_model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': 0.5,\n",
    "}\n",
    "# torch.save(checkpoint, 'checkpoint.pth')\n",
    "print(\"\\nCheckpoint includes: model weights, optimizer state, epoch, loss\")\n",
    "\n",
    "# 2. MODEL EXPORT FOR PRODUCTION\n",
    "print(\"\\n2. MODEL EXPORT FORMATS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# TorchScript (for PyTorch deployment)\n",
    "sample_model.eval()\n",
    "scripted_model = torch.jit.script(sample_model)\n",
    "# scripted_model.save('model_scripted.pt')\n",
    "print(\"TorchScript: torch.jit.script(model)\")\n",
    "print(\"  â†’ Self-contained, can run without Python\")\n",
    "\n",
    "# ONNX (Open Neural Network Exchange)\n",
    "dummy_input = torch.randn(1, 784)\n",
    "# torch.onnx.export(sample_model, dummy_input, 'model.onnx')\n",
    "print(\"\\nONNX: torch.onnx.export(model, input, 'model.onnx')\")\n",
    "print(\"  â†’ Cross-platform, works with TensorRT, CoreML, etc.\")\n",
    "\n",
    "# 3. INFERENCE OPTIMIZATION\n",
    "print(\"\\n3. INFERENCE OPTIMIZATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"Key optimizations:\")\n",
    "print(\"  1. model.eval() - Disable dropout/batchnorm training mode\")\n",
    "print(\"  2. torch.no_grad() - Disable gradient computation\")\n",
    "print(\"  3. torch.inference_mode() - More aggressive optimization\")\n",
    "print(\"  4. Model quantization - Reduce precision (FP32 â†’ INT8)\")\n",
    "print(\"  5. TorchScript/TensorRT - Compile model for hardware\")\n",
    "\n",
    "# Example inference function\n",
    "def optimized_inference(model, inputs):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():  # Faster than no_grad\n",
    "        outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "# 4. BATCHING FOR THROUGHPUT\n",
    "print(\"\\n4. BATCHING STRATEGIES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"Dynamic batching for inference servers:\")\n",
    "print(\"  - Collect requests for short time window\")\n",
    "print(\"  - Batch together and process\")\n",
    "print(\"  - Return individual results\")\n",
    "print(\"  â†’ Maximizes GPU utilization\")\n",
    "\n",
    "# 5. MODEL VERSIONING\n",
    "print(\"\\n5. MODEL VERSIONING & MLOps\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"Best practices:\")\n",
    "print(\"  - Version control model code (Git)\")\n",
    "print(\"  - Track experiments (MLflow, Weights & Biases)\")\n",
    "print(\"  - Store model artifacts (S3, GCS)\")\n",
    "print(\"  - Monitor production metrics\")\n",
    "print(\"  - A/B testing for model updates\")\n",
    "\n",
    "# 6. COMPLETE DEPLOYMENT PIPELINE\n",
    "print(\"\\n6. DEPLOYMENT OPTIONS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "deployment_options = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 Model Deployment Options                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Option          â”‚  Use Case               â”‚  Tools     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  REST API        â”‚  Web services           â”‚  FastAPI   â”‚\n",
    "â”‚  gRPC            â”‚  High-performance       â”‚  Triton    â”‚\n",
    "â”‚  Serverless      â”‚  Variable load          â”‚  Lambda    â”‚\n",
    "â”‚  Edge devices    â”‚  Low latency, privacy   â”‚  ONNX RT   â”‚\n",
    "â”‚  Mobile          â”‚  iOS/Android apps       â”‚  CoreML    â”‚\n",
    "â”‚  Embedded        â”‚  IoT devices            â”‚  TF Lite   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\"\n",
    "print(deployment_options)\n",
    "\n",
    "print(\"âœ“ Choose based on latency, throughput, and cost requirements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4254236",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŽ“ Deep Learning Complete Guide - Summary\n",
    "\n",
    "## What We Covered:\n",
    "\n",
    "### Part 1: Foundations (Beginner)\n",
    "1. **Tensors** - The fundamental data structure\n",
    "2. **Perceptrons** - Single neurons as decision makers\n",
    "3. **Activation Functions** - Non-linearity for learning complex patterns\n",
    "4. **First Neural Network** - Building blocks of deep learning\n",
    "5. **Training Loop** - Forward pass, loss, backprop, optimize\n",
    "\n",
    "### Part 2: Core Architectures (Intermediate)\n",
    "6. **Convolutional Neural Networks (CNNs)** - Spatial patterns in images\n",
    "7. **Pooling & Architecture Design** - Building effective CNNs\n",
    "8. **Recurrent Neural Networks (RNNs)** - Sequential data processing\n",
    "9. **LSTMs** - Long-range dependencies with gating\n",
    "10. **Regularization** - Preventing overfitting\n",
    "\n",
    "### Part 3: Advanced Topics\n",
    "11. **Transformers & Attention** - Foundation of modern AI\n",
    "12. **GANs** - Adversarial generative models\n",
    "13. **Transfer Learning** - Leveraging pre-trained models\n",
    "14. **Advanced Training** - LR scheduling, AMP, gradient accumulation\n",
    "15. **VAEs** - Probabilistic generative models\n",
    "16. **Deployment** - Production best practices\n",
    "\n",
    "## Next Steps:\n",
    "1. **Practice**: Implement these architectures on your own datasets\n",
    "2. **Read Papers**: Original papers provide deep insights\n",
    "3. **Experiment**: Try different hyperparameters and architectures\n",
    "4. **Build Projects**: Real projects solidify understanding\n",
    "5. **Stay Current**: Follow arXiv, conferences (NeurIPS, ICML, ICLR)\n",
    "\n",
    "## Recommended Resources:\n",
    "- **Fast.ai Course** - Practical deep learning\n",
    "- **Stanford CS231n** - CNNs for visual recognition\n",
    "- **Stanford CS224n** - NLP with deep learning\n",
    "- **\"Deep Learning\" by Goodfellow** - The DL bible\n",
    "- **PyTorch Tutorials** - Official documentation\n",
    "\n",
    "---\n",
    "**Congratulations! You now have a solid foundation in Deep Learning!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
