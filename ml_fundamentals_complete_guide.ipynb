{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0319809c",
   "metadata": {},
   "source": [
    "# ğŸš€ Machine Learning Fundamentals: Complete Guide\n",
    "\n",
    "## From Zero to ML Engineer\n",
    "\n",
    "Welcome! This notebook will teach you **machine learning model training from the ground up**. We'll cover:\n",
    "\n",
    "1. **Core Concepts** - What ML actually is and how it works\n",
    "2. **Data Handling** - Loading, exploring, and preprocessing data\n",
    "3. **Model Training** - Building and training your first models\n",
    "4. **Evaluation** - Understanding if your model is any good\n",
    "5. **Advanced Techniques** - Regularization, hyperparameter tuning, and more\n",
    "\n",
    "By the end, you'll understand **exactly** what happens when you train an ML model.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ What is Machine Learning?\n",
    "\n",
    "**Machine Learning** is teaching computers to learn patterns from data instead of explicitly programming rules.\n",
    "\n",
    "### The Three Main Types:\n",
    "- **Supervised Learning**: Learn from labeled data (input â†’ output pairs)\n",
    "  - *Regression*: Predict continuous values (house prices, temperature)\n",
    "  - *Classification*: Predict categories (spam/not spam, cat/dog)\n",
    "  \n",
    "- **Unsupervised Learning**: Find patterns in unlabeled data\n",
    "  - *Clustering*: Group similar items (customer segments)\n",
    "  - *Dimensionality Reduction*: Simplify data while keeping important info\n",
    "  \n",
    "- **Reinforcement Learning**: Learn through trial and error with rewards\n",
    "\n",
    "Let's start coding! ğŸ‘‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41a129",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Section 1: Import Required Libraries\n",
    "\n",
    "First, let's import all the essential libraries we'll need:\n",
    "\n",
    "| Library | Purpose |\n",
    "|---------|---------|\n",
    "| **NumPy** | Numerical operations, arrays |\n",
    "| **Pandas** | Data manipulation, DataFrames |\n",
    "| **Scikit-learn** | ML algorithms, preprocessing |\n",
    "| **Matplotlib/Seaborn** | Visualization |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8583c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn - the ML workhorse\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,  # Regression metrics\n",
    "    accuracy_score, precision_score, recall_score, f1_score,  # Classification metrics\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "# ML Models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# Datasets\n",
    "from sklearn.datasets import load_iris, load_wine, make_classification, make_regression\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)  # For reproducibility\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5125ffb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Section 2: Understanding Data - Loading and Exploring Datasets\n",
    "\n",
    "Before building models, you MUST understand your data. This is the **most important step** in ML.\n",
    "\n",
    "### Key Questions to Ask:\n",
    "- How many samples and features do we have?\n",
    "- What types of data (numerical, categorical)?\n",
    "- Are there missing values?\n",
    "- What's the distribution of each feature?\n",
    "- Are there correlations between features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset - a classic ML dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(\"ğŸŒ¸ IRIS DATASET - Classification Task\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Shape: {df.shape} (rows, columns)\")\n",
    "print(f\"Features: {iris.feature_names}\")\n",
    "print(f\"Target classes: {iris.target_names}\")\n",
    "print(\"\\nğŸ“‹ First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential EDA (Exploratory Data Analysis) commands\n",
    "print(\"ğŸ“Š STATISTICAL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and data types\n",
    "print(\"ğŸ“ DATA INFO\")\n",
    "print(\"=\"*50)\n",
    "print(df.info())\n",
    "print(\"\\nğŸ” Missing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "feature_cols = iris.feature_names\n",
    "\n",
    "for idx, (ax, col) in enumerate(zip(axes.flat, feature_cols)):\n",
    "    for species in df['species'].unique():\n",
    "        subset = df[df['species'] == species]\n",
    "        ax.hist(subset[col], alpha=0.7, label=species, bins=15)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'Distribution of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('ğŸ“Š Feature Distributions by Species', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7deeb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix - SUPER IMPORTANT!\n",
    "# Shows how features relate to each other\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[feature_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, fmt='.2f')\n",
    "plt.title('ğŸ”— Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ INSIGHT: High correlation between features can indicate:\")\n",
    "print(\"   - Redundant information (might drop one)\")\n",
    "print(\"   - Multicollinearity issues for some models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98149408",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ Section 3: Data Preprocessing and Feature Engineering\n",
    "\n",
    "Raw data is NEVER ready for ML models. We need to:\n",
    "\n",
    "1. **Handle Missing Values** - Impute or remove\n",
    "2. **Encode Categorical Variables** - Convert text to numbers\n",
    "3. **Scale Features** - Normalize numerical values\n",
    "4. **Feature Engineering** - Create new informative features\n",
    "\n",
    "### Why Scale Features?\n",
    "Many ML algorithms (like Gradient Descent, KNN, SVM) are sensitive to feature scales.\n",
    "If one feature ranges 0-1 and another 0-1000, the larger one dominates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset with issues to fix\n",
    "sample_data = pd.DataFrame({\n",
    "    'age': [25, 30, np.nan, 45, 50, 35, np.nan, 40],\n",
    "    'salary': [50000, 60000, 75000, np.nan, 90000, 65000, 70000, 80000],\n",
    "    'department': ['IT', 'HR', 'IT', 'Finance', 'HR', 'Finance', 'IT', 'HR'],\n",
    "    'performance': ['Good', 'Excellent', 'Good', 'Average', 'Excellent', 'Good', 'Average', 'Good']\n",
    "})\n",
    "\n",
    "print(\"ğŸ“‹ SAMPLE DATA WITH ISSUES:\")\n",
    "print(sample_data)\n",
    "print(\"\\nâŒ Missing values:\")\n",
    "print(sample_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b33f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. HANDLING MISSING VALUES\n",
    "print(\"ğŸ”§ FIXING MISSING VALUES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Strategy 1: Fill with mean (for numerical)\n",
    "sample_data['age_filled'] = sample_data['age'].fillna(sample_data['age'].mean())\n",
    "sample_data['salary_filled'] = sample_data['salary'].fillna(sample_data['salary'].median())\n",
    "\n",
    "print(\"âœ… Age filled with mean:\", round(sample_data['age'].mean(), 2))\n",
    "print(\"âœ… Salary filled with median:\", sample_data['salary'].median())\n",
    "\n",
    "# 2. ENCODING CATEGORICAL VARIABLES\n",
    "print(\"\\nğŸ”§ ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Label Encoding - assigns numbers 0, 1, 2...\n",
    "le = LabelEncoder()\n",
    "sample_data['department_encoded'] = le.fit_transform(sample_data['department'])\n",
    "print(f\"Department mapping: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
    "\n",
    "# One-Hot Encoding - creates binary columns (PREFERRED for nominal data)\n",
    "dept_onehot = pd.get_dummies(sample_data['department'], prefix='dept')\n",
    "print(f\"\\nOne-Hot columns created: {list(dept_onehot.columns)}\")\n",
    "\n",
    "sample_data = pd.concat([sample_data, dept_onehot], axis=1)\n",
    "print(\"\\nğŸ“‹ Data after preprocessing:\")\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99586ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FEATURE SCALING - Critical for many algorithms!\n",
    "print(\"âš–ï¸ FEATURE SCALING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Original data\n",
    "X_example = np.array([[25, 50000], [30, 60000], [45, 90000], [50, 100000]])\n",
    "\n",
    "# StandardScaler: Mean=0, Std=1 (Z-score normalization)\n",
    "# Formula: z = (x - Î¼) / Ïƒ\n",
    "scaler_standard = StandardScaler()\n",
    "X_standard = scaler_standard.fit_transform(X_example)\n",
    "\n",
    "# MinMaxScaler: Range [0, 1]\n",
    "# Formula: x_scaled = (x - x_min) / (x_max - x_min)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_minmax = scaler_minmax.fit_transform(X_example)\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(X_example)\n",
    "print(\"\\nAfter StandardScaler (mean=0, std=1):\")\n",
    "print(X_standard.round(2))\n",
    "print(\"\\nAfter MinMaxScaler (range 0-1):\")\n",
    "print(X_minmax.round(2))\n",
    "\n",
    "print(\"\\nğŸ’¡ WHEN TO USE WHAT:\")\n",
    "print(\"   - StandardScaler: When features should have zero mean (most algorithms)\")\n",
    "print(\"   - MinMaxScaler: When you need bounded range (neural networks, images)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf4c64",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ‚ï¸ Section 4: Splitting Data - Train, Validation, and Test Sets\n",
    "\n",
    "**THE GOLDEN RULE OF ML**: Never evaluate on data you trained on!\n",
    "\n",
    "### Why Split Data?\n",
    "- **Training Set (60-80%)**: Model learns from this\n",
    "- **Validation Set (10-20%)**: Tune hyperparameters, prevent overfitting\n",
    "- **Test Set (10-20%)**: Final, unbiased performance estimate\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        Full Dataset                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚      Training (70%)      â”‚ Validation   â”‚    Test (15%)     â”‚\n",
    "â”‚                          â”‚    (15%)     â”‚                   â”‚\n",
    "â”‚    Model learns here     â”‚ Tune params  â”‚  Final evaluation â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target from Iris dataset\n",
    "X = df[feature_cols].values  # Features (input)\n",
    "y = df['target'].values       # Target (what we predict)\n",
    "\n",
    "print(\"ğŸ“Š DATA SPLITTING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Target distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Split into train and test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42,    # Reproducibility - same split every time\n",
    "    stratify=y          # IMPORTANT: Maintain class distribution\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Training set: {len(X_train)} samples\")\n",
    "print(f\"âœ… Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nTraining class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
    "print(\"\\nğŸ’¡ 'stratify=y' ensures each class is proportionally represented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features - ALWAYS fit on training data only!\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# CRITICAL: Fit ONLY on training data, transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Learn mean/std from train\n",
    "X_test_scaled = scaler.transform(X_test)         # Apply same transformation\n",
    "\n",
    "print(\"âš ï¸ CRITICAL CONCEPT: Data Leakage Prevention\")\n",
    "print(\"=\"*50)\n",
    "print(\"âœ… Correct: fit_transform(X_train), then transform(X_test)\")\n",
    "print(\"âŒ Wrong: fit_transform on entire dataset before split\")\n",
    "print(\"\\nIf you fit on test data, you're 'peeking' at information\")\n",
    "print(\"your model shouldn't have during training!\")\n",
    "\n",
    "print(f\"\\nTrain mean before scaling: {X_train.mean(axis=0).round(2)}\")\n",
    "print(f\"Train mean after scaling: {X_train_scaled.mean(axis=0).round(4)}\")  # Should be ~0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec54cd3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ˆ Section 5: Building Your First Model - Linear Regression\n",
    "\n",
    "Let's start with the simplest model: **Linear Regression**\n",
    "\n",
    "### The Math Behind It\n",
    "\n",
    "Linear regression finds the best line that fits the data:\n",
    "\n",
    "$$\\hat{y} = X \\cdot \\theta = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n$$\n",
    "\n",
    "Where:\n",
    "- $\\hat{y}$ = predicted value\n",
    "- $\\theta$ = model parameters (weights)\n",
    "- $X$ = input features\n",
    "\n",
    "### The Normal Equation (Closed-form solution)\n",
    "\n",
    "$$\\hat{\\theta} = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "This gives us the optimal weights directly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1869dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate regression dataset\n",
    "np.random.seed(42)\n",
    "X_reg, y_reg = make_regression(n_samples=200, n_features=1, noise=20, random_state=42)\n",
    "\n",
    "# Split\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"ğŸ¯ REGRESSION DATASET\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training samples: {len(X_reg_train)}\")\n",
    "print(f\"Test samples: {len(X_reg_test)}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_reg_train, y_reg_train, alpha=0.7, label='Training data')\n",
    "plt.scatter(X_reg_test, y_reg_test, alpha=0.7, label='Test data', marker='x')\n",
    "plt.xlabel('Feature X')\n",
    "plt.ylabel('Target y')\n",
    "plt.title('ğŸ“Š Regression Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a256fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTING LINEAR REGRESSION FROM SCRATCH!\n",
    "class LinearRegressionFromScratch:\n",
    "    \"\"\"\n",
    "    Linear Regression using the Normal Equation.\n",
    "    This is EXACTLY what sklearn does under the hood!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.theta = None  # Model parameters\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model using Normal Equation: Î¸ = (X^T X)^(-1) X^T y\n",
    "        \"\"\"\n",
    "        # Add bias term (column of 1s)\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        \n",
    "        # Normal equation\n",
    "        self.theta = np.linalg.pinv(X_b.T @ X_b) @ X_b.T @ y\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return X_b @ self.theta\n",
    "\n",
    "# Train our custom model\n",
    "my_model = LinearRegressionFromScratch()\n",
    "my_model.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "# Train sklearn's model for comparison\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "print(\"ğŸ”¬ LINEAR REGRESSION FROM SCRATCH\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Our Î¸ (bias, weight): {my_model.theta.round(4)}\")\n",
    "print(f\"sklearn's intercept: {sklearn_model.intercept_:.4f}\")\n",
    "print(f\"sklearn's coefficient: {sklearn_model.coef_[0]:.4f}\")\n",
    "print(\"\\nâœ… Our implementation matches sklearn! ğŸ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ef795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fitted line\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot predictions\n",
    "X_line = np.linspace(X_reg.min(), X_reg.max(), 100).reshape(-1, 1)\n",
    "y_pred_line = my_model.predict(X_line)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_reg_train, y_reg_train, alpha=0.6, label='Training data')\n",
    "plt.plot(X_line, y_pred_line, color='red', linewidth=2, label='Fitted line')\n",
    "plt.xlabel('Feature X')\n",
    "plt.ylabel('Target y')\n",
    "plt.title('ğŸ“ˆ Linear Regression Fit')\n",
    "plt.legend()\n",
    "\n",
    "# Residuals plot\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pred_train = my_model.predict(X_reg_train)\n",
    "residuals = y_reg_train - y_pred_train\n",
    "plt.scatter(y_pred_train, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('ğŸ“Š Residuals Plot (should be random around 0)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ Good residual plot = randomly scattered around 0\")\n",
    "print(\"   Patterns in residuals suggest model is missing something!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91220a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‰ Section 6: Understanding Loss Functions and Optimization\n",
    "\n",
    "### What is a Loss Function?\n",
    "\n",
    "A **loss function** measures how wrong our predictions are. Our goal is to **minimize** it.\n",
    "\n",
    "### Mean Squared Error (MSE) - Regression\n",
    "\n",
    "$$L_{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "- Penalizes large errors more (squared)\n",
    "- Always positive\n",
    "- Smaller = better\n",
    "\n",
    "### Cross-Entropy Loss - Classification\n",
    "\n",
    "$$L_{CE} = -\\frac{1}{n}\\sum_{i=1}^{n}[y_i \\log(\\hat{y}_i) + (1-y_i)\\log(1-\\hat{y}_i)]$$\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "When we can't solve directly (like normal equation), we use **gradient descent**:\n",
    "\n",
    "$$\\theta = \\theta - \\alpha \\nabla L$$\n",
    "\n",
    "Where $\\alpha$ = learning rate, $\\nabla L$ = gradient of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Loss Functions from scratch\n",
    "def mse_loss(y_true, y_pred):\n",
    "    \"\"\"Mean Squared Error\"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mae_loss(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Error\"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def rmse_loss(y_true, y_pred):\n",
    "    \"\"\"Root Mean Squared Error\"\"\"\n",
    "    return np.sqrt(mse_loss(y_true, y_pred))\n",
    "\n",
    "# Calculate losses for our model\n",
    "y_pred_test = my_model.predict(X_reg_test)\n",
    "\n",
    "print(\"ğŸ“Š LOSS FUNCTION VALUES\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MSE:  {mse_loss(y_reg_test, y_pred_test):.4f}\")\n",
    "print(f\"RMSE: {rmse_loss(y_reg_test, y_pred_test):.4f}\")\n",
    "print(f\"MAE:  {mae_loss(y_reg_test, y_pred_test):.4f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ WHICH TO USE?\")\n",
    "print(\"   - MSE: Standard, penalizes outliers heavily\")\n",
    "print(\"   - MAE: More robust to outliers\")\n",
    "print(\"   - RMSE: Same units as target variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b444d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”„ Section 7: Training Loop - The Heart of ML\n",
    "\n",
    "This is where the magic happens! Every ML model follows this pattern:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     TRAINING LOOP                           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  1. FORWARD PASS: Make predictions using current weights    â”‚\n",
    "â”‚           â†“                                                 â”‚\n",
    "â”‚  2. CALCULATE LOSS: How wrong are we?                       â”‚\n",
    "â”‚           â†“                                                 â”‚\n",
    "â”‚  3. BACKWARD PASS: Calculate gradients (direction to move)  â”‚\n",
    "â”‚           â†“                                                 â”‚\n",
    "â”‚  4. UPDATE WEIGHTS: Î¸ = Î¸ - Î± * gradient                   â”‚\n",
    "â”‚           â†“                                                 â”‚\n",
    "â”‚  5. REPEAT until loss stops decreasing                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24489945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTING GRADIENT DESCENT FROM SCRATCH!\n",
    "class LinearRegressionGD:\n",
    "    \"\"\"\n",
    "    Linear Regression using Gradient Descent.\n",
    "    This shows you EXACTLY how neural networks learn!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.theta = None\n",
    "        self.loss_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Add bias term\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        n_samples, n_features = X_b.shape\n",
    "        \n",
    "        # Initialize weights randomly\n",
    "        self.theta = np.random.randn(n_features)\n",
    "        \n",
    "        # Training loop\n",
    "        for i in range(self.n_iterations):\n",
    "            # 1. FORWARD PASS: Make predictions\n",
    "            y_pred = X_b @ self.theta\n",
    "            \n",
    "            # 2. CALCULATE LOSS\n",
    "            loss = np.mean((y - y_pred) ** 2)\n",
    "            self.loss_history.append(loss)\n",
    "            \n",
    "            # 3. BACKWARD PASS: Calculate gradients\n",
    "            # Gradient of MSE w.r.t. theta: -2/n * X^T * (y - y_pred)\n",
    "            gradient = -2/n_samples * X_b.T @ (y - y_pred)\n",
    "            \n",
    "            # 4. UPDATE WEIGHTS\n",
    "            self.theta = self.theta - self.lr * gradient\n",
    "            \n",
    "            # Print progress\n",
    "            if (i + 1) % 200 == 0:\n",
    "                print(f\"Iteration {i+1}/{self.n_iterations}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return X_b @ self.theta\n",
    "\n",
    "# Train with gradient descent\n",
    "print(\"ğŸ”„ TRAINING WITH GRADIENT DESCENT\")\n",
    "print(\"=\"*50)\n",
    "gd_model = LinearRegressionGD(learning_rate=0.1, n_iterations=1000)\n",
    "gd_model.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "print(f\"\\nFinal Î¸: {gd_model.theta.round(4)}\")\n",
    "print(f\"Normal equation Î¸: {my_model.theta.round(4)}\")\n",
    "print(\"\\nâœ… Gradient descent converges to the same solution!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792206ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training process\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(gd_model.loss_history)\n",
    "axes[0].set_xlabel('Iteration')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('ğŸ“‰ Training Loss Over Time')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Learning rate comparison\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
    "colors = ['red', 'orange', 'green', 'blue']\n",
    "\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    model = LinearRegressionGD(learning_rate=lr, n_iterations=100)\n",
    "    model.fit(X_reg_train, y_reg_train)\n",
    "    axes[1].plot(model.loss_history, label=f'lr={lr}', color=color, alpha=0.7)\n",
    "\n",
    "axes[1].set_xlabel('Iteration')\n",
    "axes[1].set_ylabel('Loss (MSE)')\n",
    "axes[1].set_title('ğŸ“Š Effect of Learning Rate')\n",
    "axes[1].legend()\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ Learning Rate Insights:\")\n",
    "print(\"   - Too small (0.001): Slow convergence\")\n",
    "print(\"   - Too large (0.5): May overshoot and diverge\")\n",
    "print(\"   - Just right (0.01-0.1): Fast and stable convergence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c87a96f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Section 8: Evaluating Model Performance\n",
    "\n",
    "### Regression Metrics\n",
    "\n",
    "| Metric | Formula | Use When |\n",
    "|--------|---------|----------|\n",
    "| **MSE** | $\\frac{1}{n}\\sum(y-\\hat{y})^2$ | Standard, penalizes large errors |\n",
    "| **RMSE** | $\\sqrt{MSE}$ | Same units as target |\n",
    "| **MAE** | $\\frac{1}{n}\\sum|y-\\hat{y}|$ | Robust to outliers |\n",
    "| **RÂ² Score** | $1 - \\frac{SS_{res}}{SS_{tot}}$ | Interpretable (0-1 is good) |\n",
    "\n",
    "### Classification Metrics\n",
    "\n",
    "| Metric | Formula | Use When |\n",
    "|--------|---------|----------|\n",
    "| **Accuracy** | $\\frac{TP+TN}{Total}$ | Balanced classes |\n",
    "| **Precision** | $\\frac{TP}{TP+FP}$ | Cost of false positives high |\n",
    "| **Recall** | $\\frac{TP}{TP+FN}$ | Cost of false negatives high |\n",
    "| **F1 Score** | $2 \\cdot \\frac{P \\cdot R}{P+R}$ | Balance precision & recall |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeac559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESSION METRICS IN ACTION\n",
    "print(\"ğŸ“Š REGRESSION METRICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "y_pred = gd_model.predict(X_reg_test)\n",
    "\n",
    "# Calculate all metrics\n",
    "mse = mean_squared_error(y_reg_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_reg_test, y_pred)\n",
    "r2 = r2_score(y_reg_test, y_pred)\n",
    "\n",
    "print(f\"MSE:  {mse:.4f}  (lower is better)\")\n",
    "print(f\"RMSE: {rmse:.4f}  (same units as y)\")\n",
    "print(f\"MAE:  {mae:.4f}  (average error magnitude)\")\n",
    "print(f\"RÂ²:   {r2:.4f}  (1.0 = perfect, 0 = baseline)\")\n",
    "\n",
    "print(\"\\nğŸ’¡ RÂ² INTERPRETATION:\")\n",
    "print(f\"   Our model explains {r2*100:.1f}% of the variance in the target!\")\n",
    "print(f\"   A random baseline would score 0.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b261797d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Section 9: Classification - Logistic Regression\n",
    "\n",
    "Now let's tackle **classification** - predicting categories instead of numbers.\n",
    "\n",
    "### The Sigmoid Function\n",
    "\n",
    "Logistic regression uses the **sigmoid function** to squash outputs to probabilities [0, 1]:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "Where $z = X \\cdot \\theta$ (same as linear regression!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cdef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-10, 10, 100)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(z, sigmoid(z), 'b-', linewidth=2)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='Decision boundary (0.5)')\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.axhline(y=1, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.xlabel('z (input)')\n",
    "plt.ylabel('Ïƒ(z) (probability)')\n",
    "plt.title('ğŸ“ˆ Sigmoid Function: Ïƒ(z) = 1 / (1 + e^(-z))')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ KEY INSIGHT:\")\n",
    "print(\"   - Input z can be any real number (-âˆ to +âˆ)\")\n",
    "print(\"   - Output is always between 0 and 1 (probability)\")\n",
    "print(\"   - At z=0, Ïƒ(z) = 0.5 (50% probability)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1cb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary classification dataset (2 classes from Iris)\n",
    "# We'll use only setosa (0) vs versicolor (1)\n",
    "mask = df['target'] < 2\n",
    "X_binary = df.loc[mask, feature_cols].values\n",
    "y_binary = df.loc[mask, 'target'].values\n",
    "\n",
    "# Split the data\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_binary, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_clf = StandardScaler()\n",
    "X_train_clf_scaled = scaler_clf.fit_transform(X_train_clf)\n",
    "X_test_clf_scaled = scaler_clf.transform(X_test_clf)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_clf_scaled, y_train_clf)\n",
    "\n",
    "# Predictions\n",
    "y_pred_clf = log_reg.predict(X_test_clf_scaled)\n",
    "y_pred_proba = log_reg.predict_proba(X_test_clf_scaled)\n",
    "\n",
    "print(\"ğŸ¯ LOGISTIC REGRESSION CLASSIFICATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Classes: {log_reg.classes_}\")\n",
    "print(f\"\\nSample predictions:\")\n",
    "print(f\"  Actual:     {y_test_clf[:10]}\")\n",
    "print(f\"  Predicted:  {y_pred_clf[:10]}\")\n",
    "print(f\"\\nProbabilities for first 5 samples:\")\n",
    "for i in range(5):\n",
    "    print(f\"  Sample {i+1}: Class 0: {y_pred_proba[i][0]:.3f}, Class 1: {y_pred_proba[i][1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Metrics\n",
    "print(\"ğŸ“Š CLASSIFICATION METRICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "precision = precision_score(y_test_clf, y_pred_clf)\n",
    "recall = recall_score(y_test_clf, y_pred_clf)\n",
    "f1 = f1_score(y_test_clf, y_pred_clf)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}  (correct predictions / total)\")\n",
    "print(f\"Precision: {precision:.4f}  (true positives / predicted positives)\")\n",
    "print(f\"Recall:    {recall:.4f}  (true positives / actual positives)\")\n",
    "print(f\"F1 Score:  {f1:.4f}  (harmonic mean of precision & recall)\")\n",
    "\n",
    "print(\"\\nğŸ“‹ CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test_clf, y_pred_clf, target_names=['setosa', 'versicolor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcadff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_clf, y_pred_clf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Setosa', 'Versicolor'],\n",
    "            yticklabels=['Setosa', 'Versicolor'])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('ğŸ“Š Confusion Matrix')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_clf, y_pred_proba[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[1].plot(fpr, tpr, color='blue', linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'r--', label='Random Classifier')\n",
    "axes[1].fill_between(fpr, tpr, alpha=0.2)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ğŸ“ˆ ROC Curve')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ CONFUSION MATRIX EXPLAINED:\")\n",
    "print(\"   TN (top-left): Correctly predicted Setosa\")\n",
    "print(\"   FP (top-right): Predicted Versicolor, was Setosa\")\n",
    "print(\"   FN (bottom-left): Predicted Setosa, was Versicolor\")\n",
    "print(\"   TP (bottom-right): Correctly predicted Versicolor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e01c52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸŒ³ Section 10: Decision Trees and Random Forests\n",
    "\n",
    "### Decision Trees\n",
    "- Split data based on feature thresholds\n",
    "- Easy to interpret and visualize\n",
    "- Prone to overfitting\n",
    "\n",
    "### Random Forests\n",
    "- **Ensemble** of many decision trees\n",
    "- Each tree trained on random subset of data (bagging)\n",
    "- Reduces overfitting, more robust\n",
    "- The \"wisdom of the crowd\" approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree on full Iris dataset (3 classes)\n",
    "dt_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Visualize the tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_clf, \n",
    "          feature_names=iris.feature_names,\n",
    "          class_names=iris.target_names,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('ğŸŒ³ Decision Tree Visualization', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ HOW TO READ THE TREE:\")\n",
    "print(\"   - Each box shows: splitting condition, gini impurity, samples, class distribution\")\n",
    "print(\"   - Gini = 0 means pure node (all same class)\")\n",
    "print(\"   - Follow True (left) or False (right) based on condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd32595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Decision Tree vs Random Forest\n",
    "print(\"ğŸŒ² DECISION TREE vs ğŸŒ³ğŸŒ³ğŸŒ³ RANDOM FOREST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Decision Tree\n",
    "dt_pred = dt_clf.predict(X_test_scaled)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf_clf.predict(X_test_scaled)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(f\"Decision Tree Accuracy:  {dt_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy:  {rf_accuracy:.4f}\")\n",
    "\n",
    "# Feature Importance\n",
    "plt.figure(figsize=(10, 5))\n",
    "importances = rf_clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.bar(range(len(importances)), importances[indices], color='forestgreen', alpha=0.8)\n",
    "plt.xticks(range(len(importances)), [iris.feature_names[i] for i in indices], rotation=45)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('ğŸ¯ Feature Importance (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ Feature importance tells you which features the model relies on most!\")\n",
    "print(f\"   Most important: {iris.feature_names[indices[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e01c84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ Section 11: Hyperparameter Tuning with Grid Search and Cross-Validation\n",
    "\n",
    "### The Problem\n",
    "- Models have **hyperparameters** (settings we choose before training)\n",
    "- How do we find the best combination?\n",
    "\n",
    "### Cross-Validation\n",
    "Instead of a single train/validation split, we use **k-fold CV**:\n",
    "1. Split data into k equal parts (folds)\n",
    "2. Train on k-1 folds, validate on 1 fold\n",
    "3. Repeat k times, each fold being validation once\n",
    "4. Average the results\n",
    "\n",
    "This gives a more robust estimate of performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation Example\n",
    "print(\"ğŸ”„ CROSS-VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores = cross_val_score(rf_clf, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"5-Fold CV Scores: {cv_scores.round(4)}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Why CV is better than single validation split:\")\n",
    "print(\"   - Uses ALL data for both training and validation\")\n",
    "print(\"   - Gives confidence interval on performance\")\n",
    "print(\"   - Reduces variance in performance estimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search - Find the best hyperparameters\n",
    "print(\"ğŸ” GRID SEARCH CV\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 3, 5, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nâœ… Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"âœ… Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(f\"âœ… Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752de676",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ›¡ï¸ Section 12: Regularization - Preventing Overfitting\n",
    "\n",
    "### What is Overfitting?\n",
    "When a model learns the training data **too well**, including noise, and fails to generalize.\n",
    "\n",
    "### Regularization adds a penalty to large weights:\n",
    "\n",
    "**L2 Regularization (Ridge):**\n",
    "$$L = MSE + \\lambda \\sum_{j=1}^{n} \\theta_j^2$$\n",
    "\n",
    "**L1 Regularization (Lasso):**\n",
    "$$L = MSE + \\lambda \\sum_{j=1}^{n} |\\theta_j|$$\n",
    "\n",
    "Where $\\lambda$ controls regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5759075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Overfitting and Regularization\n",
    "print(\"ğŸ›¡ï¸ REGULARIZATION DEMONSTRATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a more complex dataset with some noise\n",
    "np.random.seed(42)\n",
    "X_poly = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "y_poly = 0.5 * X_poly.flatten()**2 + np.random.randn(100) * 2  # Quadratic with noise\n",
    "\n",
    "X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(\n",
    "    X_poly, y_poly, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Add polynomial features manually to create overfitting potential\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=15)\n",
    "X_poly_train_exp = poly.fit_transform(X_poly_train)\n",
    "X_poly_test_exp = poly.transform(X_poly_test)\n",
    "\n",
    "# Train models\n",
    "linear = LinearRegression()\n",
    "ridge = Ridge(alpha=1.0)  # L2 regularization\n",
    "lasso = Lasso(alpha=0.1)  # L1 regularization\n",
    "\n",
    "linear.fit(X_poly_train_exp, y_poly_train)\n",
    "ridge.fit(X_poly_train_exp, y_poly_train)\n",
    "lasso.fit(X_poly_train_exp, y_poly_train)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Model Performance (RÂ² Score):\")\n",
    "print(f\"Linear (no regularization): Train={linear.score(X_poly_train_exp, y_poly_train):.4f}, Test={linear.score(X_poly_test_exp, y_poly_test):.4f}\")\n",
    "print(f\"Ridge (L2):                 Train={ridge.score(X_poly_train_exp, y_poly_train):.4f}, Test={ridge.score(X_poly_test_exp, y_poly_test):.4f}\")\n",
    "print(f\"Lasso (L1):                 Train={lasso.score(X_poly_train_exp, y_poly_train):.4f}, Test={lasso.score(X_poly_test_exp, y_poly_test):.4f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ INSIGHT: Notice the gap between train and test for Linear!\")\n",
    "print(\"   That's overfitting. Regularization closes this gap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c275ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the difference\n",
    "plt.figure(figsize=(15, 5))\n",
    "X_plot = np.linspace(-3, 3, 200).reshape(-1, 1)\n",
    "X_plot_exp = poly.transform(X_plot)\n",
    "\n",
    "titles = ['No Regularization (Overfitting)', 'Ridge (L2)', 'Lasso (L1)']\n",
    "models = [linear, ridge, lasso]\n",
    "\n",
    "for i, (model, title) in enumerate(zip(models, titles)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.scatter(X_poly_train, y_poly_train, alpha=0.6, label='Train')\n",
    "    plt.scatter(X_poly_test, y_poly_test, alpha=0.6, marker='x', s=50, label='Test')\n",
    "    \n",
    "    y_plot = model.predict(X_plot_exp)\n",
    "    plt.plot(X_plot, y_plot, 'r-', linewidth=2, label='Model')\n",
    "    \n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.ylim(-10, 20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ‘€ Notice how unregularized model has crazy oscillations!\")\n",
    "print(\"   Ridge and Lasso produce smoother, more generalizable curves.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34265c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¾ Section 13: Saving and Loading Models\n",
    "\n",
    "Once you've trained a good model, you need to **save it** for later use!\n",
    "\n",
    "Two main options:\n",
    "1. **joblib** - Optimized for numpy arrays (recommended for sklearn)\n",
    "2. **pickle** - Python's standard serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b599e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Models\n",
    "print(\"ğŸ’¾ SAVING AND LOADING MODELS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save the best model from our grid search\n",
    "model_filename = 'best_iris_model.joblib'\n",
    "scaler_filename = 'iris_scaler.joblib'\n",
    "\n",
    "# Save model\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"âœ… Model saved to: {model_filename}\")\n",
    "\n",
    "# Save the scaler too! (IMPORTANT - you need it for new data)\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"âœ… Scaler saved to: {scaler_filename}\")\n",
    "\n",
    "# Load the model back\n",
    "loaded_model = joblib.load(model_filename)\n",
    "loaded_scaler = joblib.load(scaler_filename)\n",
    "\n",
    "# Verify it works\n",
    "test_pred_original = best_model.predict(X_test_scaled)\n",
    "test_pred_loaded = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"\\nâœ… Predictions match: {np.array_equal(test_pred_original, test_pred_loaded)}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ BEST PRACTICES:\")\n",
    "print(\"   1. Always save the scaler/preprocessor with your model\")\n",
    "print(\"   2. Use version control for model files\")\n",
    "print(\"   3. Save model metadata (training date, performance, etc.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on NEW data (inference)\n",
    "print(\"ğŸ¯ MAKING PREDICTIONS ON NEW DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Simulate new flower measurements\n",
    "new_flower = np.array([[5.1, 3.5, 1.4, 0.2]])  # [sepal_length, sepal_width, petal_length, petal_width]\n",
    "\n",
    "# IMPORTANT: Apply the same preprocessing!\n",
    "new_flower_scaled = loaded_scaler.transform(new_flower)\n",
    "\n",
    "# Make prediction\n",
    "prediction = loaded_model.predict(new_flower_scaled)\n",
    "prediction_proba = loaded_model.predict_proba(new_flower_scaled)\n",
    "\n",
    "print(f\"New flower measurements: {new_flower[0]}\")\n",
    "print(f\"Predicted class: {iris.target_names[prediction[0]]}\")\n",
    "print(f\"Confidence scores: {dict(zip(iris.target_names, prediction_proba[0].round(3)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a1374",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Summary: The Complete ML Pipeline\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                         MACHINE LEARNING PIPELINE                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                            â”‚\n",
    "â”‚   1. ğŸ“¥ DATA COLLECTION                                                    â”‚\n",
    "â”‚      â””â”€> Gather data from various sources                                  â”‚\n",
    "â”‚                                                                            â”‚\n",
    "â”‚   2. ğŸ” EXPLORATORY DATA ANALYSIS                                          â”‚\n",
    "â”‚      â””â”€> Understand distributions, correlations, outliers                  â”‚\n",
    "â”‚                                                                            â”‚\n",
    "â”‚   3. ğŸ§¹ DATA PREPROCESSING                                                 â”‚\n",
    "â”‚      â”œâ”€> Handle missing values                                             â”‚\n",
    "â”‚      â”œâ”€> Encode categorical variables                                      â”‚\n",
    "â”‚      â””â”€> Scale/normalize features                                          â”‚\n",
    "â”‚                                                                            â”‚\n",
    "â”‚   4. âœ‚ï¸ TRAIN/TEST SPLIT                                                   â”‚\n",
    "â”‚      â””â”€> Never peek at test data during training!                          â”‚\n",
    "â”‚                                                                            â”‚\n",
    "â”‚   5. ğŸ‹ï¸ MODEL TRAINING                                                     â”‚\n",
    "â”‚      â”œâ”€> Forward pass (predictions)                                        â”‚\n",
    "â”‚      â”œâ”€> Loss calculation                                                  â”‚\n",
    "â”‚      â”œâ”€> Backpropagation (gradients)                                       â”‚\n",
    "â”‚      â””â”€> Weight updates                                                    â”‚\n",
    "â”‚                                                                            â”‚\n",
    "â”‚   6. ğŸ”§ HYPERPARAMETER TUNING                                              â”‚\n",
    "â”‚      â””â”€> Grid Search / Random Search with Cross-Validation                 â”‚\n",
    "â”‚                                                                            â”‚\n",
    "â”‚   7. ğŸ“Š EVALUATION                                                         â”‚ \n",
    "â”‚      â”œâ”€> Regression: MSE, RMSE, MAE, RÂ²                                    â”‚\n",
    "â”‚      â””â”€> Classification: Accuracy, Precision, Recall, F1, ROC-AUC          â”‚\n",
    "â”‚                                                                            â”‚\n",
    "â”‚   8. ğŸ’¾ MODEL DEPLOYMENT                                                   â”‚\n",
    "â”‚      â””â”€> Save model + preprocessors for production                         â”‚\n",
    "â”‚                                                                            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## ğŸš€ Next Steps\n",
    "\n",
    "Now that you understand the fundamentals, here's what to explore next:\n",
    "\n",
    "1. **Deep Learning** - Neural networks with TensorFlow/PyTorch\n",
    "2. **Feature Engineering** - Domain-specific feature creation\n",
    "3. **More Algorithms** - SVM, KNN, XGBoost, Neural Networks\n",
    "4. **MLOps** - Model deployment, monitoring, versioning\n",
    "5. **Specialized Domains** - NLP, Computer Vision, Time Series\n",
    "\n",
    "**Remember:** The best way to learn ML is by **doing projects**! Start with Kaggle competitions.\n",
    "\n",
    "---\n",
    "*Created with â¤ï¸ for aspiring ML engineers*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
